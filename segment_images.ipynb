{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenUVF Image Segmentation\n",
    "\n",
    "Copyright Â© 2019 Southern Company Services, Inc.  All rights reserved.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhg19\\OneDrive\\Documents\\GitHub\\OpenUVF\\core\\object_detection\\utils\\visualization_utils.py:27: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n"
     ]
    }
   ],
   "source": [
    "#Import Statements\n",
    "import cv2 as cv\n",
    "import os\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import math\n",
    "import lensfunpy\n",
    "import tensorflow as tf\n",
    "import core.utils.segmentation_utils as segment\n",
    "import core.utils.detection_utils as detect\n",
    "from random import sample\n",
    "from PIL import Image as im\n",
    "from core import object_detection as object_detection\n",
    "from core.object_detection.utils import ops as utils_ops\n",
    "from core.object_detection.utils import label_map_util\n",
    "from core.object_detection.utils import visualization_utils as vis_util\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs\n",
    "\n",
    "#### Directories\n",
    "1. images_dir = string specifiying the path (local or global) to the image directory\n",
    "\n",
    "\n",
    "#### Module parameters\n",
    "1. module_orientation = string specifying the orientation of the module. Choices are 'vertical' or ' horizontal' \n",
    "2. module_aspect_ratio = float specifying the aspect ratio of the module, specified as ratio of longer side to shorter side\n",
    "\n",
    "\n",
    "#### Function Settings\n",
    "1. debug = boolean specifying if debug plots should be generated\n",
    "2. itmax = int specifying the maximum amount of refinement iterations where the segmentation routine is adjusted to increase accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "images_dir = 'workspace\\module_segmentation\\Sample Set\\FullSize'\n",
    "images_ext = '.JPG'\n",
    "output_dir = 'workspace\\module_segmentation\\Sample Set\\Processed/'\n",
    "\n",
    "# Imaging Parameters \n",
    "num_rows = 1\n",
    "module_orientation = 'horizontal'\n",
    "module_aspect_ratio = 2\n",
    "\n",
    "# Camera Distortion Parameters\n",
    "correct_distortion = True\n",
    "correct_distortion_mode = 'lensfun'\n",
    "camera_mnfcr = 'NIKON CORPORATION'\n",
    "camera_model = 'NIKON D3S'\n",
    "lens_mnfcr = 'SAMYANG'\n",
    "lens_model = 'Samyang T-S 24mm f/3.5 ED AS UMC'\n",
    "image_focal_length = 24.0\n",
    "image_aperture = 1.4\n",
    "approx_distance = 3\n",
    "camera_calibration = None\n",
    "\n",
    "# Module Detection Parameters\n",
    "path_to_frozen_graph = 'workspace/module_segmentation/models/FRCNN_RN101_v2/frozen_inference_graph.pb'\n",
    "path_to_labels = 'workspace/module_segmentation/1_Class_label_map.pbtxt'\n",
    "\n",
    "\n",
    "\n",
    "# Function Settings\n",
    "debug = True\n",
    "debug_outputs = True\n",
    "itmax = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Plotting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.keys()\n",
    "mpl.rcParams['axes.spines.bottom'] = False\n",
    "mpl.rcParams['axes.spines.left'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['xtick.bottom'] = False\n",
    "mpl.rcParams['ytick.left'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Output Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prelim_output_dir = os.path.join(output_dir, 'prelim_perspective_correction')\n",
    "detect_output_dir = os.path.join(output_dir, 'module_detection')\n",
    "final_output_dir = os.path.join(output_dir, 'final')\n",
    "debug_output_dir = os.path.join(output_dir, 'debug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDebugPlots():\n",
    "        \n",
    "    #Create figure\n",
    "    fig = plt.figure(num=f'Image {image_name} Preprocessing', tight_layout=True,figsize=[18, 9.5])\n",
    "    gs = gridspec.GridSpec(4,5)\n",
    "    mng = plt.get_current_fig_manager()\n",
    "\n",
    "    # Axis RGB - Plot base image\n",
    "    axrgb = fig.add_subplot(gs[0,0])\n",
    "    plt.imshow(rgb)\n",
    "    plt.title('RGB')\n",
    "\n",
    "    # Axis R - Plot base image\n",
    "    axr = fig.add_subplot(gs[0,1])\n",
    "    plt.imshow(red) \n",
    "    plt.title('Red')\n",
    "\n",
    "    # Axis G - Plot base image\n",
    "    axg = fig.add_subplot(gs[0,2])\n",
    "    plt.imshow(gre) \n",
    "    plt.title('Green')\n",
    "\n",
    "    # Axis B - Plot base image\n",
    "    axb = fig.add_subplot(gs[0,3])\n",
    "    plt.imshow(blu) \n",
    "    plt.title('Blue')\n",
    "\n",
    "    # Axis RGB Hist - Plot histograms of the three channels\n",
    "    axrgbhist = fig.add_subplot(gs[0,4])\n",
    "    plt.plot(red_hist, 'r-'), plt.plot(gre_hist, 'g-'), plt.plot(blu_hist, 'b-')\n",
    "    plt.xlabel('Intensity'), plt.ylabel('Count'), plt.title('RGB Histograms')\n",
    "\n",
    "    # Axis HSV - Plot image in hsv color space\n",
    "    axhsv = fig.add_subplot(gs[1,0])\n",
    "    plt.imshow(hsv)\n",
    "    plt.title('HSV')\n",
    "\n",
    "    # Axis H - Plot image in hsv color space\n",
    "    axh = fig.add_subplot(gs[1,1])\n",
    "    plt.imshow(hue)\n",
    "    plt.title('Hue')\n",
    "\n",
    "    # Axis S - Plot image in hsv color space\n",
    "    axs = fig.add_subplot(gs[1,2])\n",
    "    plt.imshow(sat)\n",
    "    plt.title('Saturation')\n",
    "\n",
    "    # Axis V - Plot image in hsv color space\n",
    "    axv = fig.add_subplot(gs[1,3])\n",
    "    plt.imshow(val)\n",
    "    plt.title('Value (brightness)')\n",
    "\n",
    "    # Axis Hist - Plot histograms of the three channels\n",
    "    axhsvhist = fig.add_subplot(gs[1,4])\n",
    "    plt.plot(hue_hist, 'k-', label = 'Hue')\n",
    "    plt.plot(sat_hist, 'm-', label = 'Sat')\n",
    "    plt.plot(val_hist, 'c-', label = 'Val')\n",
    "    plt.xlabel('Intensity'), plt.ylabel('Count'), plt.title('HSV Histograms'), plt.legend(loc='upper left')\n",
    "\n",
    "    # Axis Grau - Plot standard grayscale image\n",
    "    axgray = fig.add_subplot(gs[2,0])\n",
    "    plt.imshow(gray)\n",
    "    plt.title('Grayscale')\n",
    "\n",
    "    # Axis Gray Histogram\n",
    "    axgrayhist = fig.add_subplot(gs[2,1])\n",
    "    gray_hist = cv.calcHist([gray], [0], None, [256], [0, 256])\n",
    "    plt.plot(gray_hist, 'k-')\n",
    "    plt.title('Grayscale Histogram')\n",
    "\n",
    "    # Axis RGB min - Plot standard grayscale image\n",
    "    axgray = fig.add_subplot(gs[2,2])\n",
    "    plt.imshow(rgb_min)\n",
    "    plt.title('RGB Min (min of each channel)')\n",
    "\n",
    "    # Axis RGB min Histogram\n",
    "    axgrayhist = fig.add_subplot(gs[2,3])\n",
    "    rgb_min_hist = cv.calcHist([rgb_min], [0], None, [256], [0, 256])\n",
    "    plt.plot(rgb_min_hist, 'k-')\n",
    "    plt.title('RGB min Histogram')\n",
    "\n",
    "    # Axis RGB min edges \n",
    "    axhe = fig.add_subplot(gs[3,0])\n",
    "    plt.imshow(edges_rgb_min)\n",
    "    plt.title('RGB Min Edges')\n",
    "\n",
    "    # Axis Gray edges - Plot showing the edges detected in the standard grayscale image\n",
    "    axhe = fig.add_subplot(gs[3,1])\n",
    "    plt.imshow(edges_gray)\n",
    "    plt.title('Grayscale Edges')\n",
    "\n",
    "    # Axis Hue edges - Plot showing the edge\n",
    "    axhe = fig.add_subplot(gs[3,2])\n",
    "    plt.imshow(edges_hue)\n",
    "    plt.title('Hue Edges')\n",
    "\n",
    "    # Axis final edges - Plot showing the edge\n",
    "    axhe = fig.add_subplot(gs[3,3])\n",
    "    plt.imshow(edges)\n",
    "    plt.title('Edges')\n",
    "\n",
    "    # Axis Hue Lines - Plot detected lines \n",
    "    axhe = fig.add_subplot(gs[3,4])\n",
    "    plt.imshow(gray_bgr)\n",
    "    plt.title('Detected Lines (Hough)')\n",
    "\n",
    "    #Create Second figure\n",
    "    fig2 = plt.figure(num=f'Image {image_name} Segmentation', tight_layout=True,figsize=[18, 9.5])\n",
    "    gs2 = gridspec.GridSpec(2,3)\n",
    "    mng2 = plt.get_current_fig_manager()\n",
    "\n",
    "    #Selected representative perspective lines\n",
    "    axls = fig2.add_subplot(gs2[0,0])\n",
    "    plt.imshow(gray_sample_lines)\n",
    "    plt.title('Projective Transform Sample Lines')\n",
    "\n",
    "    #Vanishing point plot\n",
    "    axvps = fig2.add_subplot(gs2[0,1])\n",
    "    plt.imshow(gray_bgr)\n",
    "    plt.plot(vert_vanish_xs, vert_vanish_ys, 'b.')\n",
    "    plt.plot(vert_vanish_pt[0], vert_vanish_pt[1], 'r.', markersize=16)  \n",
    "    plt.plot(hori_vanish_xs, hori_vanish_ys, 'g.')\n",
    "    plt.xlim(-10000, 10000), plt.ylim(-10000, 10000)\n",
    "    plt.title('Vanishing Points')\n",
    "\n",
    "    #Projective Transform Geometry Calculations Plot\n",
    "    axptg = fig2.add_subplot(gs2[0,2])\n",
    "    plt.imshow(gray_sample_box)\n",
    "    plt.title('Projective Transform Geometry')\n",
    "\n",
    "    #Projective Transform \n",
    "    axptg = fig2.add_subplot(gs2[1,0])\n",
    "    plt.imshow(transed)\n",
    "    plt.title('Projective Transform')\n",
    "\n",
    "    #Update figure and Pause\n",
    "    plt.draw()\n",
    "    fig.canvas.manager.window.raise_()\n",
    "    plt.pause(0.01)\n",
    "    \n",
    "    #Save all images as files\n",
    "    if debug_outputs:\n",
    "        \n",
    "        # Sample lines \n",
    "        output_path = os.path.join(debug_output_dir, image_root + '_lines' + images_ext)\n",
    "        cv.imwrite(output_path, cv.cvtColor(gray_sample_lines, cv.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Sample Boxes \n",
    "        output_path = os.path.join(debug_output_dir, image_root + '_boxes' + images_ext)\n",
    "        cv.imwrite(output_path, cv.cvtColor(gray_sample_box, cv.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Debug figures \n",
    "        output_path = os.path.join(debug_output_dir, image_root + '_debug_1' + images_ext)\n",
    "        fig.savefig(output_path)\n",
    "        output_path = os.path.join(debug_output_dir, image_root + '_debug_2' + images_ext)\n",
    "        fig2.savefig(output_path)\n",
    "        \n",
    "        #Close figures\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib \n",
    "# Define list of images in the specified directory (NEEDS EDGE HANDLING)\n",
    "image_list = os.listdir(images_dir)\n",
    "image_list = [image_name for image_name in image_list if image_name.endswith(images_ext)]\n",
    "\n",
    "# Predefined global image processing parameters\n",
    "resize_rows = 600 \n",
    "resize_cols = 902            #only used when running module detection alone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Perspective Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Image DSC03003.JPG (1):\n",
      "   Image Loading:\n",
      "      Aspect Ratio: 1.50\n",
      "      Image Size is 2832 x 4240 (12007680 px.)\n",
      "      Image Resized to 600 x 898 (538800 px.)\n",
      "   Camera Distortion Correction:\n",
      "      Correction applied for NIKON D3S with Samyang T-S 24mm f/3.5 ED AS UMC.\n",
      "   Image Statistics:\n",
      "      RGB Means: red = 123.14; blue = 104.39; green = 74.86\n",
      "      HSV Means: hue = 139.96; saturation = 147.06; value = 137.81\n",
      "   Edge Detection:\n",
      "      (0): Ratio = 0.61%\n",
      "   Line Detection:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\numpy\\core\\_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "C:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\numpy\\core\\_methods.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "C:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\numpy\\core\\_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      (0): 91 Lines Detected - 87 Filtered - 2 Horizontal (2.38 +- 2.43 deg.) - 2 Vertical (96.20 +- 5.18 deg.)\n",
      "   Projective Transform:\n",
      "      Perspective correction successful!\n",
      "   Processing time: 1.2855 s\n",
      "\n",
      "Processing Image DSC03013.JPG (2):\n",
      "   Image Loading:\n",
      "      Aspect Ratio: 1.50\n",
      "      Image Size is 2832 x 4240 (12007680 px.)\n",
      "      Image Resized to 600 x 898 (538800 px.)\n",
      "   Camera Distortion Correction:\n",
      "      Correction applied for NIKON D3S with Samyang T-S 24mm f/3.5 ED AS UMC.\n",
      "   Image Statistics:\n",
      "      RGB Means: red = 97.06; blue = 121.51; green = 60.91\n",
      "      HSV Means: hue = 139.00; saturation = 149.42; value = 128.87\n",
      "   Edge Detection:\n",
      "      (0): Ratio = 0.41%\n",
      "   Line Detection:\n",
      "      (0): 77 Lines Detected - 73 Filtered - 2 Horizontal (0.62 +- 0.72 deg.) - 2 Vertical (93.56 +- 3.16 deg.)\n",
      "   Projective Transform:\n",
      "      Perspective correction successful!\n",
      "   Processing time: 1.1789 s\n",
      "\n",
      "Processing Image DSC03021.JPG (3):\n",
      "   Image Loading:\n",
      "      Aspect Ratio: 1.50\n",
      "      Image Size is 2832 x 4240 (12007680 px.)\n",
      "      Image Resized to 600 x 898 (538800 px.)\n",
      "   Camera Distortion Correction:\n",
      "      Correction applied for NIKON D3S with Samyang T-S 24mm f/3.5 ED AS UMC.\n",
      "   Image Statistics:\n",
      "      RGB Means: red = 119.83; blue = 123.45; green = 89.52\n",
      "      HSV Means: hue = 134.38; saturation = 136.62; value = 143.58\n",
      "   Edge Detection:\n",
      "      (0): Ratio = 0.66%\n",
      "   Line Detection:\n",
      "      (0): 197 Lines Detected - 193 Filtered - 2 Horizontal (6.17 +- 1.20 deg.) - 2 Vertical (96.73 +- 2.04 deg.)\n",
      "   Projective Transform:\n",
      "      Perspective correction successful!\n",
      "   Processing time: 1.2883 s\n",
      "\n",
      "Processing Image DSC03022.JPG (4):\n",
      "   Image Loading:\n",
      "      Aspect Ratio: 1.50\n",
      "      Image Size is 2832 x 4240 (12007680 px.)\n",
      "      Image Resized to 600 x 898 (538800 px.)\n",
      "   Camera Distortion Correction:\n",
      "      Correction applied for NIKON D3S with Samyang T-S 24mm f/3.5 ED AS UMC.\n",
      "   Image Statistics:\n",
      "      RGB Means: red = 115.08; blue = 126.89; green = 93.01\n",
      "      HSV Means: hue = 130.13; saturation = 129.03; value = 141.84\n",
      "   Edge Detection:\n",
      "      (0): Ratio = 0.69%\n",
      "   Line Detection:\n",
      "      (0): 199 Lines Detected - 195 Filtered - 2 Horizontal (6.28 +- 0.45 deg.) - 2 Vertical (96.19 +- 3.18 deg.)\n",
      "   Projective Transform:\n",
      "      Perspective correction successful!\n",
      "   Processing time: 1.3843 s\n",
      "\n",
      "Processing Image DSC03023.JPG (5):\n",
      "   Image Loading:\n",
      "      Aspect Ratio: 1.50\n",
      "      Image Size is 2832 x 4240 (12007680 px.)\n",
      "      Image Resized to 600 x 898 (538800 px.)\n",
      "   Camera Distortion Correction:\n",
      "      Correction applied for NIKON D3S with Samyang T-S 24mm f/3.5 ED AS UMC.\n",
      "   Image Statistics:\n",
      "      RGB Means: red = 106.10; blue = 116.35; green = 75.74\n",
      "      HSV Means: hue = 133.57; saturation = 143.19; value = 132.37\n",
      "   Edge Detection:\n",
      "      (0): Ratio = 0.69%\n",
      "   Line Detection:\n",
      "      (0): 219 Lines Detected - 215 Filtered - 2 Horizontal (4.15 +- 0.58 deg.) - 2 Vertical (94.23 +- 2.44 deg.)\n",
      "   Projective Transform:\n",
      "      Perspective correction successful!\n",
      "   Processing time: 1.3410 s\n",
      "\n",
      "Processing Image DSC03024.JPG (6):\n",
      "   Image Loading:\n",
      "      Aspect Ratio: 1.50\n",
      "      Image Size is 2832 x 4240 (12007680 px.)\n",
      "      Image Resized to 600 x 898 (538800 px.)\n",
      "   Camera Distortion Correction:\n",
      "      Correction applied for NIKON D3S with Samyang T-S 24mm f/3.5 ED AS UMC.\n",
      "   Image Statistics:\n",
      "      RGB Means: red = 96.09; blue = 103.99; green = 58.71\n",
      "      HSV Means: hue = 139.69; saturation = 145.49; value = 115.90\n",
      "   Edge Detection:\n",
      "      (0): Ratio = 0.59%\n",
      "   Line Detection:\n",
      "      (0): 183 Lines Detected - 179 Filtered - 2 Horizontal (5.29 +- 0.31 deg.) - 2 Vertical (95.99 +- 1.97 deg.)\n",
      "   Projective Transform:\n",
      "      Perspective correction successful!\n",
      "   Processing time: 1.3649 s\n",
      "\n",
      "Processing Image DSC03025.JPG (7):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-45ebe0dc678d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m#Load image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mimage_original\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m#Calculate basic parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Processing steps\n",
    "equalize_hist = False\n",
    "equalize_method = 'global'\n",
    "    \n",
    "#iterate through images\n",
    "image_it = 1\n",
    "for image_name in image_list:\n",
    "    \n",
    "    #Log start time\n",
    "    time_start = time.time()\n",
    "    \n",
    "    #Debug Outputs\n",
    "    print(f'\\nProcessing Image {image_name} ({image_it}):') \n",
    "    \n",
    "    #Define image path\n",
    "    image_root = os.path.splitext(image_name)[0]\n",
    "    image_path = images_dir + '/' + image_name\n",
    "    \n",
    "    #Load image\n",
    "    image_original = cv.imread(image_path)\n",
    "    \n",
    "    #Calculate basic parameters\n",
    "    image_rows, image_cols, image_channels = image_original.shape;\n",
    "    aspect_ratio = image_cols/image_rows\n",
    "    image_pixels = image_cols * image_rows\n",
    "    image_scalar = resize_rows/image_rows\n",
    "    resize_cols = round(aspect_ratio * resize_rows)\n",
    "    resize_pixels = resize_rows * resize_cols\n",
    "    print(f'   Image Loading:')\n",
    "    print(f'      Aspect Ratio: {aspect_ratio:.2f}')\n",
    "    print(f'      Image Size is {image_rows} x {image_cols} ({image_pixels} px.)')\n",
    "    print(f'      Image Resized to {resize_rows} x {resize_cols} ({resize_pixels} px.)')\n",
    "    \n",
    "    #Distortion correction - POSSIBLY IMPLEMENT - May cause more distortion than it corrects\n",
    "    if correct_distortion:\n",
    "        \n",
    "        #Print update statement\n",
    "        print('   Camera Distortion Correction:')\n",
    "        \n",
    "        if correct_distortion_mode == 'lensfun':                 #Corrects using lensfunpy, which uses the lensfun database\n",
    "            \n",
    "            #Error Handling\n",
    "            try: \n",
    "                \n",
    "                #Load camera and lens information\n",
    "                lensfun_db = lensfunpy.Database()\n",
    "                camera = lensfun_db.find_cameras(camera_mnfcr, camera_model)[0]\n",
    "                lens = lensfun_db.find_lenses(camera, lens_mnfcr, lens_model)[0]\n",
    "\n",
    "                #Correct distortion\n",
    "                distortion_modifier = lensfunpy.Modifier(lens, camera.crop_factor, image_cols, image_rows)\n",
    "                distortion_modifier.initialize(image_focal_length, image_aperture, approx_distance)\n",
    "                undistorted_coords = distortion_modifier.apply_geometry_distortion()\n",
    "                undistorted = cv.remap(image_original, undistorted_coords, None, cv.INTER_LANCZOS4)\n",
    "                \n",
    "                #Print update\n",
    "                print(f'      Correction applied for {camera_model} with {lens_model}.')\n",
    "                \n",
    "            except Exception:\n",
    "                \n",
    "                print(Exception)\n",
    "                \n",
    "                #Print update\n",
    "                print(f'      Correction failed. Invalid camera or lens inputs.')\n",
    "            \n",
    "        elif correct_distortion_mode == 'camera_calibration':     #Uses an existing calibration file from calibrate_camera utility\n",
    "            \n",
    "            x=y\n",
    "            \n",
    "        else:\n",
    "            print('      Distortion Correction Failed. Check inputs')\n",
    "            undistorted = image_original\n",
    "    \n",
    "    #Resize image to nominal size to increase computation speed(and adjust the anticipated aspect ratio as well)\n",
    "    \n",
    "    image = cv.resize(undistorted, (resize_cols, resize_rows))\n",
    "        \n",
    "    #NEED PREPROCESSING STEP WHICH ADJUSTS THE WHITE BALANCE SOMEHOW - WHEN IMAGING, WB should be constant\n",
    "    \n",
    "    #Convert to RGB and isolate channels\n",
    "    rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    rgb_min = np.amin(rgb, axis=2)\n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    red = rgb[:,:,0]\n",
    "    gre = rgb[:,:,1]\n",
    "    blu = rgb[:,:,2]\n",
    "    \n",
    "    #Calculate RGB statistics from the image \n",
    "    red_mean = np.mean(red)\n",
    "    red_hist = cv.calcHist([rgb], [0], None, [256], [0, 256])\n",
    "    gre_mean = np.mean(gre)\n",
    "    gre_hist = cv.calcHist([gre], [0], None, [256], [0, 256])\n",
    "    blu_mean = np.mean(blu)\n",
    "    blu_hist = cv.calcHist([blu], [0], None, [256], [0, 256])\n",
    "    print(f'   Image Statistics:')\n",
    "    print(f'      RGB Means: red = {red_mean:.2f};'\\\n",
    "          f' blue = {blu_mean:.2f}; green = {gre_mean:.2f}')\n",
    "    \n",
    "    \n",
    "    #Convert to HSV and isolate channels\n",
    "    hsv = cv.cvtColor(rgb, cv.COLOR_RGB2HSV)\n",
    "    hue = hsv[:,:,0]\n",
    "    sat = hsv[:,:,1]\n",
    "    val = hsv[:,:,2]\n",
    "    \n",
    "    #Calculate HSV statistics from the image\n",
    "    #hue = hue.astype(np.float64)\n",
    "    #hue[hue < 48] = hue + 48\n",
    "    hue_mean = np.mean(hue)\n",
    "    hue_hist = cv.calcHist([hue], [0], None, [256], [0, 256])\n",
    "    sat_mean = np.mean(sat)\n",
    "    sat_hist = cv.calcHist([sat], [0], None, [256], [0, 256])\n",
    "    val_mean = np.mean(val)\n",
    "    val_hist = cv.calcHist([val], [0], None, [256], [0, 256])\n",
    "    print(f'      HSV Means: hue = {hue_mean:.2f};'\\\n",
    "          f' saturation = {sat_mean:.2f}; value = {val_mean:.2f}')\n",
    "\n",
    "    #Detect if image is particularly dark \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Histogram Equalization\n",
    "    if equalize_hist and (equalize_method == 'adaptive'):\n",
    "        clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(9,9))\n",
    "        rgb_min = clahe.apply(rgb_min)\n",
    "        gray = clahe.apply(gray)\n",
    "        hue = clahe.apply(hue)\n",
    "    elif equalize_hist and (equalize_method == 'global'):\n",
    "        rgb_min = cv.equalizeHist(rgb_min)\n",
    "        gray = cv.equalizeHist(gray)\n",
    "        hue = cv.equalizeHist(hue)\n",
    "    \n",
    "    \n",
    "    #Iteratively refine detected edges in the images\n",
    "    edges, edge_outputs = segment.edgeDetection(rgb, rgb_min, gray, hue, image_pixels, debug=debug)\n",
    "    rgb_min_smooth = edge_outputs['rgb_min_smooth']\n",
    "    gray_smooth = edge_outputs['gray_smooth']\n",
    "    edges_rgb_min = edge_outputs['edges_rgb_min']\n",
    "    edges_gray = edge_outputs['edges_gray']\n",
    "    edges_hue = edge_outputs['edges_hue']\n",
    "    \n",
    "    #Detect prominent lines\n",
    "    print('   Line Detection:')\n",
    "    max_std = 1                                     #STD cutoff for line deviation\n",
    "    min_line_length = 150\n",
    "    max_line_gap = 10\n",
    "    hough_threshold = 100\n",
    "    hough_theta = np.pi/1080\n",
    "    hough_rho = 1\n",
    "    line_it = 0\n",
    "    line_repeat = True\n",
    "    while line_repeat & (line_it < 10):\n",
    "    \n",
    "        #Calculate lines with specified parameters\n",
    "        lines, line_points, line_points_edge, line_angles = segment.lineDetection(edges, hough_rho, hough_theta, \\\n",
    "                                                                                  hough_threshold, min_line_length,\\\n",
    "                                                                                  max_line_gap, resize_rows, resize_cols, \\\n",
    "                                                                                  debug=debug)\n",
    "        \n",
    "        #Filter lines \n",
    "        vert_inds, vert_lines, vert_angles, hori_inds, hori_lines, hori_angles, reject_inds, reject_lines, line_outputs \\\n",
    "            = segment.filterLines(lines, line_points, line_angles, hough_theta, debug = True)\n",
    "        \n",
    "        #Extract additional outputs\n",
    "        vert_angles_mean = line_outputs['vert_angles_mean']\n",
    "        vert_angles_std = line_outputs['vert_angles_std']\n",
    "        hori_angles_mean = line_outputs['hori_angles_mean']\n",
    "        hori_angles_std = line_outputs['hori_angles_std']\n",
    "        \n",
    "        #Determine vanishing points\n",
    "        vert_vanish_pt = line_outputs['vert_vanish_pt']\n",
    "        vert_vanish_xs = line_outputs['vert_vanish_xs']   \n",
    "        vert_vanish_ys = line_outputs['vert_vanish_ys']\n",
    "        hori_vanish_xs = []\n",
    "        hori_vanish_ys = []\n",
    "        \n",
    "        #Count number of final lines\n",
    "        num_lines = len(lines)\n",
    "        num_hori_lines = len(hori_lines)\n",
    "        num_vert_lines = len(vert_lines)\n",
    "        num_lines_filtered = num_lines -(num_hori_lines + num_vert_lines)\n",
    "        \n",
    "        #Determine if the line detection procedure should be repeated and strengthen or weaken parameters to achieve this\n",
    "        max_ct = 250\n",
    "        min_ct = 2      \n",
    "        if (num_vert_lines < min_ct) or (num_hori_lines < min_ct):\n",
    "            line_repeat = True\n",
    "            min_line_length *= 0.9 \n",
    "            max_line_gap *= 1.25 \n",
    "            max_std *= 1.1\n",
    "        elif (num_vert_lines > max_ct) or (num_hori_lines > max_ct):\n",
    "            line_repeat = True\n",
    "            min_line_length = 1.1 * min_line_length\n",
    "            max_line_gap = 0.9 * max_line_gap\n",
    "            max_std *= 0.75\n",
    "        else:\n",
    "            line_repeat = False\n",
    "            \n",
    "        #Output update\n",
    "        print(f'      ({line_it}): {num_lines} Lines Detected - {num_lines_filtered} Filtered - '\\\n",
    "              f'{num_hori_lines} Horizontal ({hori_angles_mean:.2f} +- {hori_angles_std:.2f} deg.)',\\\n",
    "              f'- {num_vert_lines} Vertical ({vert_angles_mean:.2f} +- {vert_angles_std:.2f} deg.)')\n",
    "        \n",
    "        #Iterate iteration counter\n",
    "        line_it = line_it + 1\n",
    "        \n",
    "        #Failure update\n",
    "        if line_repeat and (line_it == 10):\n",
    "            print('      Line Detection Failed - Image Rejected')\n",
    "        \n",
    "\n",
    "    #Plot lines on the image\n",
    "    if debug:\n",
    "        gray_bgr = cv.cvtColor(gray_smooth, cv.COLOR_GRAY2BGR)\n",
    "        gray_bgr = segment.plotLines(gray_bgr, vert_lines, hori_lines, reject_lines)\n",
    "        gray_bgr_extended = cv.cvtColor(gray_smooth, cv.COLOR_GRAY2BGR)\n",
    "        gray_bgr_extended = segment.plotLines(gray, None, None, None, all_lines = line_points_edge)\n",
    "    \n",
    "    \n",
    "    #Plot vanishing points and perspective lines\n",
    "    #if debug:\n",
    "    #    gray_vanish_pts = gray_bgr\n",
    "    #    for v in range(0,len(vert_vanish_xs)):\n",
    "    #        if not (math.isnan(vert_vanish_xs[v])) and not (math.isnan(vert_vanish_ys[v])):\n",
    "    #            cv.circle(gray_vanish_pts, (int(vert_vanish_xs[v]), int(vert_vanish_ys[v])), 1, (0,128,255), thickness=-1)\n",
    "    #    for h in range(0,len(hori_vanish_xs)):\n",
    "    #        if not (math.isnan(hori_vanish_xs[h])) and not (math.isnan(hori_vanish_ys[h])):\n",
    "    #            cv.circle(gray_vanish_pts, (int(hori_vanish_xs[h]), int(hori_vanish_ys[h])), 1, (0,255,128), thickness=-1)\n",
    "            \n",
    "    #Select 4 representative lines - 2 Horizontal and 2 Vertical\n",
    "    #vert_lines_sort = np.argsort(vert_angles)\n",
    "    #vert_lines = vert_lines[vert_lines_sort]\n",
    "    #hori_lines_sort = np.argsort(hori_angles)\n",
    "    #hori_lines = hori_lines[hori_lines_sort]\n",
    "\n",
    "    #PASTE HERE\n",
    "    \n",
    "    #Calculate mean projective transform\n",
    "    print('   Projective Transform:')\n",
    "    transed, proj_trans, rot_ang, gray_sample_lines, gray_sample_box = segment.projectiveTransform(image_original, lines,\\\n",
    "                                                                                                   vert_inds, hori_inds,\\\n",
    "                                                                                                   gray_smooth, resize_rows,\\\n",
    "                                                                                                   image_scalar, hough_theta)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Save image\n",
    "    transed = cv.cvtColor(transed, cv.COLOR_BGR2RGB)\n",
    "    output_path = os.path.join(prelim_output_dir, image_root + '_output' + images_ext)\n",
    "    try:\n",
    "        cv.imwrite(output_path, cv.cvtColor(transed, cv.COLOR_BGR2RGB))\n",
    "    except OSError:\n",
    "        os.mkdir(prelim_output_dir)\n",
    "        cv.imwrite(output_path, cv.cvtColor(transed, cv.COLOR_BGR2RGB))\n",
    "    \n",
    "    #Log end time and calculate total execution time\n",
    "    time_end = time.time()\n",
    "    time_execute = time_end - time_start\n",
    "    print(f'   Processing time: {time_execute:0.4f} s')\n",
    "    \n",
    "    #Generate debug plots\n",
    "    if debug:\n",
    "        generateDebugPlots()\n",
    "        \n",
    "    #Iteration counter    \n",
    "    image_it += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Detection with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module Detection Setup:\n",
      "   315 images found in directory.\n",
      "   Frozen TensorFlow model loaded.\n",
      "   Model initialized.\n",
      "\n",
      "Processing Image DSC03003_output.JPG (1):\n",
      "   2 modules detected.\n",
      "   Edge Detection:\n",
      "      (0): Ratio = 18.77%\n",
      "   Line Detection:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ad02c9530605>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m                 \u001b[1;31m#Final Perspective Correction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m                 \u001b[0mcorrectModulePerspective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrop_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-48bdc23b121a>\u001b[0m in \u001b[0;36mcorrectModulePerspective\u001b[1;34m(module_bgr, debug)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "#Detection Parameters\n",
    "probability_thresh = 0.5\n",
    "broaden_frac = 0.05                  # Scalar for the amount the detection box edges are dilated\n",
    "shard_images_count = 1\n",
    "pipeline_type = 'modules'\n",
    "\n",
    "#Update user\n",
    "print('Module Detection Setup:')\n",
    "\n",
    "#Load label map\n",
    "category_index = label_map_util.create_category_index_from_labelmap(path_to_labels, use_display_name=True)\n",
    "\n",
    "#Load image pipeline\n",
    "image_list = os.listdir(prelim_output_dir)\n",
    "image_list = [image_name for image_name in image_list if image_name.endswith('output'+images_ext)]\n",
    "image_ct = len(image_list)\n",
    "print(f'   {image_ct} images found in directory.')\n",
    "\n",
    "#Load frozen model into memory\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(path_to_frozen_graph, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "        print(f'   Frozen TensorFlow model loaded.')\n",
    "\n",
    "graph = detection_graph\n",
    "with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        ops = tf.get_default_graph().get_operations()\n",
    "        all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "        tensor_dict = {}\n",
    "        for key in [\n",
    "            'num_detections', 'detection_boxes', 'detection_scores',\n",
    "            'detection_classes', 'detection_masks'\n",
    "        ]:\n",
    "            tensor_name = key + ':0'\n",
    "            if tensor_name in all_tensor_names:\n",
    "                tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                    tensor_name)\n",
    "        if 'detection_masks' in tensor_dict:\n",
    "            # The following processing is only for single image\n",
    "            detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "            detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "            \n",
    "            # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "            real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "            detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "            detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "            detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "            detection_masks_reframed = tf.cast(\n",
    "                tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "            \n",
    "            # Follow the convention by adding back the batch dimension\n",
    "            tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "                detection_masks_reframed, 0)\n",
    "            \n",
    "        #Define Image Tensor\n",
    "        image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')   \n",
    "        print(f'   Model initialized.\\n')\n",
    "        \n",
    "        \n",
    "        #TEMPORARY - DEFINE IMAGE SIZE - FUTURE USE SIZE FROM PIPELINE\n",
    "        image_size = (resize_cols, resize_rows)\n",
    "        \n",
    "        #Iterate through images shards\n",
    "        it = 1\n",
    "        for image_name in image_list:\n",
    "            \n",
    "            #Initialize time tracking\n",
    "            batch_start_time = time.time()\n",
    "            \n",
    "            #User feedback\n",
    "            print(f'Processing Image {image_name} ({it}):')\n",
    "\n",
    "            #Load the images\n",
    "            image_root = os.path.splitext(image_name)[0]\n",
    "            image_path = os.path.join(prelim_output_dir, image_name)\n",
    "            image = im.open(image_path).resize(image_size)\n",
    "            np_image = [detect.load_image_into_numpy_array(image)]\n",
    "            cv_image = np_image[0].copy()\n",
    "            \n",
    "            #Run Detection for Image Set        \n",
    "            start_time = time.time()\n",
    "            outputs = detect.run_inference(sess, np_image, detection_graph, tensor_dict, image_tensor)           \n",
    "\n",
    "            #Count number of modules detected\n",
    "            num_modules = len(np.where(outputs[0]['detection_scores'] >= probability_thresh)[0])\n",
    "            print(f'   {num_modules} modules detected.')\n",
    "            \n",
    "            #Log Statistics\n",
    "            #statistics = log_statistics(statistics, probability_thresh, outputs, image_list, np_images)\n",
    "            \n",
    "            #Assemble Module\n",
    "            #np_images, image_list, outputs = assemble_module(np_images, image_list, outputs)\n",
    "            \n",
    "            #Generate Visualizations on images\n",
    "            np_image_labeled = detect.build_visualization(np_image, outputs, category_index, probability_thresh)\n",
    "            \n",
    "            #Saving the images\n",
    "            detect.output_images(np_image_labeled, [image_name], detect_output_dir)\n",
    "            \n",
    "            #Calculate module statistics\n",
    "            module_boxes = [outputs[0]['detection_boxes'][i] for i in range(0,num_modules)]\n",
    "            module_widths = [module_boxes[i][3] - module_boxes[i][1] for i in range(0,num_modules)]\n",
    "            module_heights = [module_boxes[i][2] - module_boxes[i][0] for i in range(0,num_modules)]\n",
    "            module_spacing = [module_boxes[i+1][3] - module_boxes[i][3] for i in range(0,num_modules-1)]\n",
    "            \n",
    "            #Crop the image to the box\n",
    "            crop_images = []\n",
    "            for m in range(0,num_modules):\n",
    "                \n",
    "                #Pull initial coordinates\n",
    "                box = module_boxes[m]\n",
    "                y1 = int(resize_cols * box[1])\n",
    "                y2 = int(resize_cols * box[3])\n",
    "                x1 = int(resize_rows * box[0])\n",
    "                x2 = int(resize_rows * box[2])\n",
    "                \n",
    "                #Broaden the box to account for errors\n",
    "                width = module_widths[m]\n",
    "                height = module_heights[m]\n",
    "                x_adj = int(height * broaden_frac * resize_rows)\n",
    "                y_adj = int(width * broaden_frac * resize_cols)\n",
    "                y1 -= y_adj\n",
    "                y2 += y_adj\n",
    "                x1 -= x_adj\n",
    "                x2 += x_adj\n",
    "                if x1 < 0:\n",
    "                    x1 = 0\n",
    "                if x2 > (resize_rows - 1):\n",
    "                    x2 = resize_rows - 1\n",
    "                if y1 < 0:\n",
    "                    y1 = 0\n",
    "                if y2 > (resize_cols - 1):\n",
    "                    y2 = resize_cols - 1\n",
    "                    \n",
    "                #Crop image and size\n",
    "                crop_image = cv_image[x1:x2, y1:y2, :]    \n",
    "                crop_rows, crop_cols, crop_channels = crop_image.shape\n",
    "                crop_pixels = crop_rows * crop_cols\n",
    "                \n",
    "                #Store and save cropped image\n",
    "                crop_images.append(crop_image)\n",
    "                output_name = image_root + f'-{m}' + images_ext\n",
    "                output_path = os.path.join(final_output_dir, output_name)\n",
    "                cv.imwrite(output_path, cv.cvtColor(crop_image, cv.COLOR_BGR2RGB))\n",
    "                \n",
    "                #Color space conversion\n",
    "                crop_gray = cv.cvtColor(crop_image, cv.COLOR_BGR2GRAY)\n",
    "                \n",
    "                #Final Perspective Correction\n",
    "                correctModulePerspective(crop_image, debug=debug)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #Perspective Correction\n",
    "                \n",
    "                \n",
    "                \n",
    "                #Binarization\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #Segmentation\n",
    "                \n",
    "                \n",
    "                #Debug outputs\n",
    "                if debug:\n",
    "                    \n",
    "                    #Create figure\n",
    "                    fig = plt.figure(num=f'Image {image_name} Preprocessing', tight_layout=True,figsize=[18, 9.5])\n",
    "                    gs = gridspec.GridSpec(4,5)\n",
    "                    mng = plt.get_current_fig_manager()\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "          \n",
    "            \n",
    "            \n",
    "            #Feedback\n",
    "            print('   Image processed successfully!\\n')\n",
    "            \n",
    "            #Count which batch\n",
    "            it += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Perspective Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctModulePerspective(module_bgr, debug=True):\n",
    "    \n",
    "    #Print update\n",
    "    print('   Module Perspective Correction:')\n",
    "    \n",
    "    #Create debug figure \n",
    "    if debug:\n",
    "        module_fig = plt.figure(num=f'Module Perspective Correction Debug', tight_layout=True,figsize=[18, 9.5])\n",
    "        gs = gridspec.GridSpec(2,3)\n",
    "        mng = plt.get_current_fig_manager()\n",
    "    \n",
    "    #Alternative color space representations\n",
    "    module_rgb = cv.cvtColor(module_bgr, cv.COLOR_BGR2RGB)\n",
    "    module_gray = cv.cvtColor(module_bgr, cv.COLOR_BGR2GRAY)\n",
    "    module_rgb_min = np.amin(module_rgb, axis=2)\n",
    "    module_hsv = cv.cvtColor(module_bgr, cv.COLOR_BGR2HSV)\n",
    "    module_hue = module_hsv[:,:,0]\n",
    "    if debug:\n",
    "        axo = module_fig.add_subplot(gs[0,0])\n",
    "        plt.imshow(module_gray)\n",
    "        plt.title('Module Grayscale')\n",
    "    \n",
    "    \n",
    "    #Calculate image dimensions\n",
    "    module_rows, module_cols, module_channels = module_bgr.shape\n",
    "    module_pixels = module_rows * module_cols\n",
    "    print(f'      Image Size is {module_rows} x {module_cols} ({module_pixels} px.)')\n",
    "    \n",
    "    #Define edge detection parameters\n",
    "    edge_params = dict()\n",
    "    edge_params['gauss_size'] = (25,25)\n",
    "    edge_params['gauss_std'] = 3\n",
    "    edge_params['canny_thresh_min'] = 150\n",
    "    edge_params['canny_thresh_max'] = 220\n",
    "    edge_params['edge_ratio_goal'] = 0.1\n",
    "    edge_params['edge_ratio_range'] = (0.01, 0.20)\n",
    "    \n",
    "    \n",
    "    #Edge Detection  \n",
    "    module_edges, module_edge_outputs = segment.edgeDetection(module_rgb, module_rgb_min, module_gray, module_hue, module_pixels, params=edge_params, debug=debug)\n",
    "    if debug:\n",
    "        axe = module_fig.add_subplot(gs[0,1])\n",
    "        plt.imshow(module_edges)\n",
    "        plt.title('Module Edges')\n",
    "    \n",
    "    #Define line detection parameters\n",
    "    print('      Line Detection:')\n",
    "    max_std = 1                                     #STD cutoff for line deviation\n",
    "    min_line_length = int(0.5 * module_rows)\n",
    "    max_line_gap = int(0.1 * min_line_length)\n",
    "    hough_threshold = 100\n",
    "    hough_theta = np.pi/1080\n",
    "    hough_rho = 1\n",
    "    line_it = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Line Detection \n",
    "    line_it = 0\n",
    "    line_repeat = True\n",
    "    while line_repeat & (line_it < 10):\n",
    "        \n",
    "        #Detect lines\n",
    "        lines, line_points, line_points_edge, line_angles = segment.lineDetection(module_edges, hough_rho, hough_theta, \\\n",
    "                                                                                  hough_threshold, min_line_length,\\\n",
    "                                                                                  max_line_gap, module_rows, module_cols, \\\n",
    "                                                                                  debug=debug)\n",
    "        #Filter lines \n",
    "        vert_inds, vert_lines, vert_angles, hori_inds, hori_lines, hori_angles, reject_inds, reject_lines, line_outputs \\\n",
    "            = segment.filterLines(lines, line_points, line_angles, hough_theta, debug = True)\n",
    "    \n",
    "    \n",
    "        #Count number of final lines\n",
    "        num_lines = len(lines)\n",
    "        num_hori_lines = len(hori_lines)\n",
    "        num_vert_lines = len(vert_lines)\n",
    "        num_lines_filtered = num_lines -(num_hori_lines + num_vert_lines)\n",
    "        \n",
    "        #Calculate perspective correction\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Redetect lines and determine parallelity\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Determine if line detection should be repeated\n",
    "        line_repeat = False\n",
    "    \n",
    "    #Plot lines in image and display\n",
    "    if debug:\n",
    "        \n",
    "        #Plot segments detected\n",
    "        lines_bgr = segment.plotLines(module_bgr, vert_lines, hori_lines, reject_lines)\n",
    "        axls = module_fig.add_subplot(gs[1,0])\n",
    "        plt.imshow(lines_bgr)\n",
    "        plt.title('Detected line segments')\n",
    "        \n",
    "        #Plot the segments extended to the edges\n",
    "        lines_bgr_extended = segment.plotLines(module_bgr, None, None, None, all_lines = line_points_edge)\n",
    "        axlse = module_fig.add_subplot(gs[1,1])\n",
    "        plt.imshow(lines_bgr_extended)\n",
    "        plt.title('Extended line segments')\n",
    "    \n",
    "    \n",
    "    x=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 454,
   "position": {
    "height": "40px",
    "left": "1303px",
    "right": "20px",
    "top": "100px",
    "width": "609px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
