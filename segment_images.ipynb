{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenUVF Image Segmentation\n",
    "\n",
    "Copyright Â© 2019 Southern Company Services, Inc.  All rights reserved.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhg19\\OneDrive\\Documents\\GitHub\\OpenUVF\\core\\object_detection\\utils\\visualization_utils.py:27: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n"
     ]
    }
   ],
   "source": [
    "#Import Statements\n",
    "import cv2 as cv\n",
    "import os\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import math\n",
    "import lensfunpy\n",
    "import tensorflow as tf\n",
    "import core.utils.segmentation_utils as segment\n",
    "import core.utils.detection_utils as detect\n",
    "from random import sample\n",
    "from PIL import Image as im\n",
    "from core import object_detection as object_detection\n",
    "from core.object_detection.utils import ops as utils_ops\n",
    "from core.object_detection.utils import label_map_util\n",
    "from core.object_detection.utils import visualization_utils as vis_util\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs\n",
    "\n",
    "#### Directories\n",
    "1. images_dir = string specifiying the path (local or global) to the image directory\n",
    "\n",
    "\n",
    "#### Module parameters\n",
    "1. module_orientation = string specifying the orientation of the module. Choices are 'vertical' or ' horizontal' \n",
    "2. module_aspect_ratio = float specifying the aspect ratio of the module, specified as ratio of longer side to shorter side\n",
    "\n",
    "\n",
    "#### Function Settings\n",
    "1. debug = boolean specifying if debug plots should be generated\n",
    "2. itmax = int specifying the maximum amount of refinement iterations where the segmentation routine is adjusted to increase accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "images_dir = 'workspace\\module_segmentation\\Sample Set\\FullSize'\n",
    "images_ext = '.JPG'\n",
    "output_dir = 'workspace\\module_segmentation\\Sample Set\\Processed/'\n",
    "\n",
    "# Imaging Parameters \n",
    "num_rows = 1\n",
    "module_orientation = 'horizontal'\n",
    "module_aspect_ratio = 2\n",
    "camera_orientation = 'landscape'\n",
    "\n",
    "# Camera Distortion Parameters\n",
    "correct_distortion = True\n",
    "correct_distortion_mode = 'lensfun'\n",
    "camera_mnfcr = 'NIKON CORPORATION'\n",
    "camera_model = 'NIKON D3S'\n",
    "lens_mnfcr = 'SAMYANG'\n",
    "lens_model = 'Samyang T-S 24mm f/3.5 ED AS UMC'\n",
    "image_focal_length = 24.0\n",
    "image_aperture = 1.4\n",
    "approx_distance = 3\n",
    "camera_calibration = None\n",
    "\n",
    "# Module Detection Parameters\n",
    "path_to_frozen_graph = 'workspace/module_segmentation/models/FRCNN_RN101_v2/frozen_inference_graph.pb'\n",
    "path_to_labels = 'workspace/module_segmentation/1_Class_label_map.pbtxt'\n",
    "\n",
    "\n",
    "\n",
    "# Function Settings\n",
    "debug = True\n",
    "debug_outputs = True\n",
    "itmax = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Plotting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.keys()\n",
    "mpl.rcParams['axes.spines.bottom'] = False\n",
    "mpl.rcParams['axes.spines.left'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['xtick.bottom'] = False\n",
    "mpl.rcParams['ytick.left'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Output Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prelim_output_dir = os.path.join(output_dir, 'prelim_perspective_correction')\n",
    "detect_output_dir = os.path.join(output_dir, 'module_detection')\n",
    "final_output_dir = os.path.join(output_dir, 'final')\n",
    "prelim_debug_output_dir = os.path.join(output_dir, 'prelim_debug')\n",
    "module_debug_output_dir = os.path.join(output_dir, 'module_debug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDebugPlots():\n",
    "        \n",
    "    #Create figure\n",
    "    fig = plt.figure(num=f'Image {image_name} Preprocessing', tight_layout=True,figsize=[18, 9.5])\n",
    "    gs = gridspec.GridSpec(4,5)\n",
    "    mng = plt.get_current_fig_manager()\n",
    "\n",
    "    # Axis RGB - Plot base image\n",
    "    axrgb = fig.add_subplot(gs[0,0])\n",
    "    plt.imshow(rgb)\n",
    "    plt.title('RGB')\n",
    "\n",
    "    # Axis R - Plot base image\n",
    "    axr = fig.add_subplot(gs[0,1])\n",
    "    plt.imshow(red) \n",
    "    plt.title('Red')\n",
    "\n",
    "    # Axis G - Plot base image\n",
    "    axg = fig.add_subplot(gs[0,2])\n",
    "    plt.imshow(gre) \n",
    "    plt.title('Green')\n",
    "\n",
    "    # Axis B - Plot base image\n",
    "    axb = fig.add_subplot(gs[0,3])\n",
    "    plt.imshow(blu) \n",
    "    plt.title('Blue')\n",
    "\n",
    "    # Axis RGB Hist - Plot histograms of the three channels\n",
    "    axrgbhist = fig.add_subplot(gs[0,4])\n",
    "    plt.plot(red_hist, 'r-'), plt.plot(gre_hist, 'g-'), plt.plot(blu_hist, 'b-')\n",
    "    plt.xlabel('Intensity'), plt.ylabel('Count'), plt.title('RGB Histograms')\n",
    "\n",
    "    # Axis HSV - Plot image in hsv color space\n",
    "    axhsv = fig.add_subplot(gs[1,0])\n",
    "    plt.imshow(hsv)\n",
    "    plt.title('HSV')\n",
    "\n",
    "    # Axis H - Plot image in hsv color space\n",
    "    axh = fig.add_subplot(gs[1,1])\n",
    "    plt.imshow(hue)\n",
    "    plt.title('Hue')\n",
    "\n",
    "    # Axis S - Plot image in hsv color space\n",
    "    axs = fig.add_subplot(gs[1,2])\n",
    "    plt.imshow(sat)\n",
    "    plt.title('Saturation')\n",
    "\n",
    "    # Axis V - Plot image in hsv color space\n",
    "    axv = fig.add_subplot(gs[1,3])\n",
    "    plt.imshow(val)\n",
    "    plt.title('Value (brightness)')\n",
    "\n",
    "    # Axis Hist - Plot histograms of the three channels\n",
    "    axhsvhist = fig.add_subplot(gs[1,4])\n",
    "    plt.plot(hue_hist, 'k-', label = 'Hue')\n",
    "    plt.plot(sat_hist, 'm-', label = 'Sat')\n",
    "    plt.plot(val_hist, 'c-', label = 'Val')\n",
    "    plt.xlabel('Intensity'), plt.ylabel('Count'), plt.title('HSV Histograms'), plt.legend(loc='upper left')\n",
    "\n",
    "    # Axis Grau - Plot standard grayscale image\n",
    "    axgray = fig.add_subplot(gs[2,0])\n",
    "    plt.imshow(gray)\n",
    "    plt.title('Grayscale')\n",
    "\n",
    "    # Axis Gray Histogram\n",
    "    axgrayhist = fig.add_subplot(gs[2,1])\n",
    "    gray_hist = cv.calcHist([gray], [0], None, [256], [0, 256])\n",
    "    plt.plot(gray_hist, 'k-')\n",
    "    plt.title('Grayscale Histogram')\n",
    "\n",
    "    # Axis RGB min - Plot standard grayscale image\n",
    "    axgray = fig.add_subplot(gs[2,2])\n",
    "    plt.imshow(rgb_min)\n",
    "    plt.title('RGB Min (min of each channel)')\n",
    "\n",
    "    # Axis RGB min Histogram\n",
    "    axgrayhist = fig.add_subplot(gs[2,3])\n",
    "    rgb_min_hist = cv.calcHist([rgb_min], [0], None, [256], [0, 256])\n",
    "    plt.plot(rgb_min_hist, 'k-')\n",
    "    plt.title('RGB min Histogram')\n",
    "\n",
    "    # Axis RGB min edges \n",
    "    axhe = fig.add_subplot(gs[3,0])\n",
    "    plt.imshow(edges_rgb_min)\n",
    "    plt.title('RGB Min Edges')\n",
    "\n",
    "    # Axis Gray edges - Plot showing the edges detected in the standard grayscale image\n",
    "    axhe = fig.add_subplot(gs[3,1])\n",
    "    plt.imshow(edges_gray)\n",
    "    plt.title('Grayscale Edges')\n",
    "\n",
    "    # Axis Hue edges - Plot showing the edge\n",
    "    axhe = fig.add_subplot(gs[3,2])\n",
    "    plt.imshow(edges_hue)\n",
    "    plt.title('Hue Edges')\n",
    "\n",
    "    # Axis final edges - Plot showing the edge\n",
    "    axhe = fig.add_subplot(gs[3,3])\n",
    "    plt.imshow(edges)\n",
    "    plt.title('Edges')\n",
    "\n",
    "    # Axis Hue Lines - Plot detected lines \n",
    "    axhe = fig.add_subplot(gs[3,4])\n",
    "    plt.imshow(gray_bgr)\n",
    "    plt.title('Detected Lines (Hough)')\n",
    "\n",
    "    #Create Second figure\n",
    "    fig2 = plt.figure(num=f'Image {image_name} Perspective Correction', tight_layout=True,figsize=[18, 9.5])\n",
    "    gs2 = gridspec.GridSpec(2,3)\n",
    "    mng2 = plt.get_current_fig_manager()\n",
    "\n",
    "    \n",
    "\n",
    "    #Vanishing point plot\n",
    "    if len(vert_vanish_pt) >= 2:\n",
    "        axvps = fig2.add_subplot(gs2[0,1])\n",
    "        plt.imshow(gray_bgr)\n",
    "        plt.plot(vert_vanish_xs, vert_vanish_ys, 'b.')\n",
    "        plt.plot(vert_vanish_pt[0], vert_vanish_pt[1], 'r.', markersize=16)  \n",
    "        plt.plot(hori_vanish_xs, hori_vanish_ys, 'g.')\n",
    "        plt.xlim(-10000, 10000), plt.ylim(-10000, 10000)\n",
    "        plt.title('Vanishing Points')\n",
    "\n",
    "    #Projective transform plots\n",
    "    if sufficient_lines:\n",
    "    \n",
    "        #Selected representative perspective lines\n",
    "        axls = fig2.add_subplot(gs2[0,0])\n",
    "        plt.imshow(gray_sample_lines)\n",
    "        plt.title('Projective Transform Sample Lines')\n",
    "    \n",
    "        #Projective Transform Geometry Calculations Plot\n",
    "        axptg = fig2.add_subplot(gs2[0,2])\n",
    "        plt.imshow(gray_sample_box)\n",
    "        plt.title('Projective Transform Geometry')\n",
    "\n",
    "        #Projective Transform \n",
    "        axptg = fig2.add_subplot(gs2[1,0])\n",
    "        plt.imshow(transed)\n",
    "        plt.title('Projective Transform')\n",
    "\n",
    "    #Update figure and Pause\n",
    "    plt.draw()\n",
    "    fig.canvas.manager.window.raise_()\n",
    "    plt.pause(0.01)\n",
    "    \n",
    "    #Save all images as files\n",
    "    if debug_outputs:\n",
    "        \n",
    "        # Sample lines \n",
    "        output_path = os.path.join(prelim_debug_output_dir, image_root + '_lines' + images_ext)\n",
    "        cv.imwrite(output_path, cv.cvtColor(gray_sample_lines, cv.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Sample Boxes \n",
    "        output_path = os.path.join(prelim_debug_output_dir, image_root + '_boxes' + images_ext)\n",
    "        cv.imwrite(output_path, cv.cvtColor(gray_sample_box, cv.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Debug figures \n",
    "        output_path = os.path.join(prelim_debug_output_dir, image_root + '_debug_1' + images_ext)\n",
    "        fig.savefig(output_path)\n",
    "        output_path = os.path.join(prelim_debug_output_dir, image_root + '_debug_2' + images_ext)\n",
    "        fig2.savefig(output_path)\n",
    "        \n",
    "        #Close figures\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib \n",
    "# Define list of images in the specified directory (NEEDS EDGE HANDLING)\n",
    "image_list = os.listdir(images_dir)\n",
    "image_list = [image_name for image_name in image_list if image_name.endswith(images_ext)]\n",
    "\n",
    "# Predefined global image processing parameters\n",
    "resize_rows = 600 \n",
    "resize_cols = 902            #only used when running module detection alone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Perspective Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Image DSC03003.JPG (1):\n",
      "   Image Loading:\n",
      "      Aspect Ratio: 1.50\n",
      "      Image Size is 2832 x 4240 (12007680 px.)\n",
      "      Image Resized to 600 x 898 (538800 px.)\n",
      "   Camera Distortion Correction:\n",
      "      Correction applied for NIKON D3S with Samyang T-S 24mm f/3.5 ED AS UMC.\n",
      "   Image Statistics:\n",
      "      RGB Means: red = 123.14; blue = 104.39; green = 74.86\n",
      "      HSV Means: hue = 139.96; saturation = 147.06; value = 137.81\n",
      "   Edge Detection:\n",
      "      (0): Ratio = 0.59%\n",
      "   Line Detection:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\numpy\\core\\_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "C:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\numpy\\core\\_methods.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "C:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\numpy\\core\\_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      (0): 80 Lines Detected - 76 Filtered - 2 Horizontal (2.21 +- 1.87 deg.) - 2 Vertical (96.16 +- 4.70 deg.)\n",
      "   Projective Transform:\n",
      "   Processing time: 1.6378 s\n",
      "\n",
      "Processing Image DSC03013.JPG (2):\n",
      "   Image Loading:\n",
      "      Aspect Ratio: 1.50\n",
      "      Image Size is 2832 x 4240 (12007680 px.)\n",
      "      Image Resized to 600 x 898 (538800 px.)\n",
      "   Camera Distortion Correction:\n",
      "      Correction applied for NIKON D3S with Samyang T-S 24mm f/3.5 ED AS UMC.\n",
      "   Image Statistics:\n",
      "      RGB Means: red = 97.06; blue = 121.51; green = 60.91\n",
      "      HSV Means: hue = 139.00; saturation = 149.42; value = 128.87\n",
      "   Edge Detection:\n",
      "      (0): Ratio = 0.52%\n",
      "   Line Detection:\n",
      "      (0): 113 Lines Detected - 109 Filtered - 2 Horizontal (0.65 +- 0.68 deg.) - 2 Vertical (93.41 +- 2.91 deg.)\n",
      "   Projective Transform:\n",
      "   Processing time: 1.5612 s\n",
      "\n",
      "Processing Image DSC03021.JPG (3):\n",
      "   Image Loading:\n",
      "      Aspect Ratio: 1.50\n",
      "      Image Size is 2832 x 4240 (12007680 px.)\n",
      "      Image Resized to 600 x 898 (538800 px.)\n",
      "   Camera Distortion Correction:\n",
      "      Correction applied for NIKON D3S with Samyang T-S 24mm f/3.5 ED AS UMC.\n",
      "   Image Statistics:\n",
      "      RGB Means: red = 119.83; blue = 123.45; green = 89.52\n",
      "      HSV Means: hue = 134.38; saturation = 136.62; value = 143.58\n",
      "   Edge Detection:\n",
      "      (0): Ratio = 0.64%\n",
      "   Line Detection:\n",
      "      (0): 181 Lines Detected - 177 Filtered - 2 Horizontal (6.04 +- 0.42 deg.) - 2 Vertical (96.57 +- 2.31 deg.)\n",
      "   Projective Transform:\n",
      "   Processing time: 1.5398 s\n",
      "\n",
      "Processing Image DSC03022.JPG (4):\n",
      "   Image Loading:\n",
      "      Aspect Ratio: 1.50\n",
      "      Image Size is 2832 x 4240 (12007680 px.)\n",
      "      Image Resized to 600 x 898 (538800 px.)\n",
      "   Camera Distortion Correction:\n",
      "      Correction applied for NIKON D3S with Samyang T-S 24mm f/3.5 ED AS UMC.\n",
      "   Image Statistics:\n",
      "      RGB Means: red = 115.08; blue = 126.89; green = 93.01\n",
      "      HSV Means: hue = 130.13; saturation = 129.03; value = 141.84\n",
      "   Edge Detection:\n",
      "      (0): Ratio = 0.67%\n",
      "   Line Detection:\n",
      "      (0): 193 Lines Detected - 189 Filtered - 2 Horizontal (6.33 +- 0.39 deg.) - 2 Vertical (95.90 +- 3.17 deg.)\n",
      "   Projective Transform:\n",
      "   Processing time: 1.9022 s\n",
      "\n",
      "Processing Image DSC03023.JPG (5):\n",
      "   Image Loading:\n",
      "      Aspect Ratio: 1.50\n",
      "      Image Size is 2832 x 4240 (12007680 px.)\n",
      "      Image Resized to 600 x 898 (538800 px.)\n",
      "   Camera Distortion Correction:\n",
      "      Correction applied for NIKON D3S with Samyang T-S 24mm f/3.5 ED AS UMC.\n",
      "   Image Statistics:\n",
      "      RGB Means: red = 106.10; blue = 116.35; green = 75.74\n",
      "      HSV Means: hue = 133.57; saturation = 143.19; value = 132.37\n",
      "   Edge Detection:\n",
      "      (0): Ratio = 0.72%\n",
      "   Line Detection:\n",
      "      (0): 226 Lines Detected - 222 Filtered - 2 Horizontal (4.15 +- 0.67 deg.) - 2 Vertical (94.71 +- 2.15 deg.)\n",
      "   Projective Transform:\n",
      "   Processing time: 1.5930 s\n",
      "\n",
      "Processing Image DSC03024.JPG (6):\n",
      "   Image Loading:\n",
      "      Aspect Ratio: 1.50\n",
      "      Image Size is 2832 x 4240 (12007680 px.)\n",
      "      Image Resized to 600 x 898 (538800 px.)\n",
      "   Camera Distortion Correction:\n",
      "      Correction applied for NIKON D3S with Samyang T-S 24mm f/3.5 ED AS UMC.\n",
      "   Image Statistics:\n",
      "      RGB Means: red = 96.09; blue = 103.99; green = 58.71\n",
      "      HSV Means: hue = 139.69; saturation = 145.49; value = 115.90\n",
      "   Edge Detection:\n",
      "      (0): Ratio = 0.68%\n",
      "   Line Detection:\n",
      "      (0): 186 Lines Detected - 182 Filtered - 2 Horizontal (5.28 +- 0.33 deg.) - 2 Vertical (96.28 +- 2.18 deg.)\n",
      "   Projective Transform:\n",
      "   Processing time: 1.6597 s\n",
      "\n",
      "Processing Image DSC03025.JPG (7):\n",
      "   Image Loading:\n",
      "      Aspect Ratio: 1.50\n",
      "      Image Size is 2832 x 4240 (12007680 px.)\n",
      "      Image Resized to 600 x 898 (538800 px.)\n",
      "   Camera Distortion Correction:\n",
      "      Correction applied for NIKON D3S with Samyang T-S 24mm f/3.5 ED AS UMC.\n",
      "   Image Statistics:\n",
      "      RGB Means: red = 99.11; blue = 110.81; green = 62.03\n",
      "      HSV Means: hue = 139.57; saturation = 143.98; value = 122.26\n",
      "   Edge Detection:\n",
      "      (0): Ratio = 0.67%\n",
      "   Line Detection:\n",
      "      (0): 153 Lines Detected - 149 Filtered - 2 Horizontal (1.65 +- 0.42 deg.) - 2 Vertical (92.63 +- 1.98 deg.)\n",
      "   Projective Transform:\n",
      "   Processing time: 1.6194 s\n",
      "\n",
      "Processing Image DSC03026.JPG (8):\n",
      "   Image Loading:\n",
      "      Aspect Ratio: 1.50\n",
      "      Image Size is 2832 x 4240 (12007680 px.)\n",
      "      Image Resized to 600 x 898 (538800 px.)\n",
      "   Camera Distortion Correction:\n",
      "      Correction applied for NIKON D3S with Samyang T-S 24mm f/3.5 ED AS UMC.\n",
      "   Image Statistics:\n",
      "      RGB Means: red = 102.34; blue = 108.03; green = 62.58\n",
      "      HSV Means: hue = 139.66; saturation = 142.95; value = 120.89\n",
      "   Edge Detection:\n",
      "      (0): Ratio = 0.63%\n",
      "   Line Detection:\n",
      "      (0): 181 Lines Detected - 177 Filtered - 2 Horizontal (7.77 +- 0.26 deg.) - 2 Vertical (98.65 +- 2.18 deg.)\n",
      "   Projective Transform:\n",
      "   Processing time: 1.5559 s\n",
      "\n",
      "Processing Image DSC03027.JPG (9):\n",
      "   Image Loading:\n",
      "      Aspect Ratio: 1.50\n",
      "      Image Size is 2832 x 4240 (12007680 px.)\n",
      "      Image Resized to 600 x 898 (538800 px.)\n",
      "   Camera Distortion Correction:\n",
      "      Correction applied for NIKON D3S with Samyang T-S 24mm f/3.5 ED AS UMC.\n",
      "   Image Statistics:\n",
      "      RGB Means: red = 96.32; blue = 97.01; green = 55.71\n",
      "      HSV Means: hue = 143.79; saturation = 152.03; value = 113.55\n",
      "   Edge Detection:\n",
      "      (0): Ratio = 0.54%\n",
      "   Line Detection:\n",
      "      (0): 143 Lines Detected - 139 Filtered - 2 Horizontal (7.21 +- 0.26 deg.) - 2 Vertical (96.61 +- 1.66 deg.)\n",
      "   Projective Transform:\n",
      "   Processing time: 1.4589 s\n",
      "\n",
      "Processing Image DSC03028.JPG (10):\n",
      "   Image Loading:\n",
      "      Aspect Ratio: 1.50\n",
      "      Image Size is 2832 x 4240 (12007680 px.)\n",
      "      Image Resized to 600 x 898 (538800 px.)\n",
      "   Camera Distortion Correction:\n",
      "      Correction applied for NIKON D3S with Samyang T-S 24mm f/3.5 ED AS UMC.\n",
      "   Image Statistics:\n",
      "      RGB Means: red = 110.18; blue = 117.47; green = 81.47\n",
      "      HSV Means: hue = 139.48; saturation = 139.01; value = 132.26\n",
      "   Edge Detection:\n",
      "      (0): Ratio = 0.58%\n",
      "   Line Detection:\n",
      "      (0): 192 Lines Detected - 188 Filtered - 2 Horizontal (9.20 +- 0.36 deg.) - 2 Vertical (99.48 +- 1.73 deg.)\n",
      "   Projective Transform:\n",
      "   Processing time: 1.8220 s\n",
      "\n",
      "Processing Image DSC03029.JPG (11):\n",
      "   Image Loading:\n",
      "      Aspect Ratio: 1.50\n",
      "      Image Size is 2832 x 4240 (12007680 px.)\n",
      "      Image Resized to 600 x 898 (538800 px.)\n",
      "   Camera Distortion Correction:\n",
      "      Correction applied for NIKON D3S with Samyang T-S 24mm f/3.5 ED AS UMC.\n",
      "   Image Statistics:\n",
      "      RGB Means: red = 109.81; blue = 122.64; green = 83.82\n",
      "      HSV Means: hue = 135.47; saturation = 134.41; value = 136.41\n",
      "   Edge Detection:\n",
      "      (0): Ratio = 0.73%\n",
      "   Line Detection:\n",
      "      (0): 232 Lines Detected - 228 Filtered - 2 Horizontal (7.48 +- 0.33 deg.) - 2 Vertical (97.17 +- 2.86 deg.)\n",
      "   Projective Transform:\n",
      "   Processing time: 1.6810 s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\matplotlib\\backends\\backend_qt5.py\u001b[0m in \u001b[0;36m_draw_idle\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m             \u001b[1;31m# Uncaught exceptions are fatal for PyQt5, so catch them instead.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    400\u001b[0m         \u001b[0mtoolbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoolbar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m             \u001b[1;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[1;31m# don't forget to call the superclass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1648\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[1;32m-> 1649\u001b[1;33m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[0;32m   1650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1651\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'figure'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, inframe)\u001b[0m\n\u001b[0;32m   2601\u001b[0m         \u001b[1;31m# will draw the edges\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2602\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxison\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_frameon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2603\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2605\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0martists_rasterized\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\matplotlib\\patches.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[0mtpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_path_non_affine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0maffine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_affine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_path_effects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mget_affine\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2460\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2461\u001b[0m             return Affine2D(np.dot(self._b.get_affine().get_matrix(),\n\u001b[1;32m-> 2462\u001b[1;33m                                 self._a.get_affine().get_matrix()))\n\u001b[0m\u001b[0;32m   2463\u001b[0m     \u001b[0mget_affine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_affine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mget_affine\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2460\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2461\u001b[0m             return Affine2D(np.dot(self._b.get_affine().get_matrix(),\n\u001b[1;32m-> 2462\u001b[1;33m                                 self._a.get_affine().get_matrix()))\n\u001b[0m\u001b[0;32m   2463\u001b[0m     \u001b[0mget_affine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_affine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mget_matrix\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2639\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2640\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2641\u001b[1;33m             \u001b[0moutl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_boxout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2642\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0moutw\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mouth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2643\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Transforming to a singular bounding box.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mbounds\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    426\u001b[0m         :attr:`height`).\n\u001b[0;32m    427\u001b[0m         \"\"\"\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_points\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Processing steps\n",
    "equalize_hist = False\n",
    "equalize_method = 'global'\n",
    "    \n",
    "#iterate through images\n",
    "image_it = 1\n",
    "for image_name in image_list:\n",
    "    \n",
    "    #Log start time\n",
    "    time_start = time.time()\n",
    "    \n",
    "    #Debug Outputs\n",
    "    print(f'\\nProcessing Image {image_name} ({image_it}):') \n",
    "    \n",
    "    #Define image path\n",
    "    image_root = os.path.splitext(image_name)[0]\n",
    "    image_path = images_dir + '/' + image_name\n",
    "    \n",
    "    #Load image\n",
    "    image_original = cv.imread(image_path)\n",
    "    \n",
    "    #Calculate basic parameters\n",
    "    image_rows, image_cols, image_channels = image_original.shape;\n",
    "    aspect_ratio = image_cols/image_rows\n",
    "    image_pixels = image_cols * image_rows\n",
    "    image_scalar = resize_rows/image_rows\n",
    "    resize_cols = round(aspect_ratio * resize_rows)\n",
    "    resize_pixels = resize_rows * resize_cols\n",
    "    print(f'   Image Loading:')\n",
    "    print(f'      Aspect Ratio: {aspect_ratio:.2f}')\n",
    "    print(f'      Image Size is {image_rows} x {image_cols} ({image_pixels} px.)')\n",
    "    print(f'      Image Resized to {resize_rows} x {resize_cols} ({resize_pixels} px.)')\n",
    "    \n",
    "    #Distortion correction - POSSIBLY IMPLEMENT - May cause more distortion than it corrects\n",
    "    if correct_distortion:\n",
    "        \n",
    "        #Print update statement\n",
    "        print('   Camera Distortion Correction:')\n",
    "        \n",
    "        if correct_distortion_mode == 'lensfun':                 #Corrects using lensfunpy, which uses the lensfun database\n",
    "            \n",
    "            #Error Handling\n",
    "            try: \n",
    "                \n",
    "                #Load camera and lens information\n",
    "                lensfun_db = lensfunpy.Database()\n",
    "                camera = lensfun_db.find_cameras(camera_mnfcr, camera_model)[0]\n",
    "                lens = lensfun_db.find_lenses(camera, lens_mnfcr, lens_model)[0]\n",
    "\n",
    "                #Correct distortion\n",
    "                distortion_modifier = lensfunpy.Modifier(lens, camera.crop_factor, image_cols, image_rows)\n",
    "                distortion_modifier.initialize(image_focal_length, image_aperture, approx_distance)\n",
    "                undistorted_coords = distortion_modifier.apply_geometry_distortion()\n",
    "                undistorted = cv.remap(image_original, undistorted_coords, None, cv.INTER_LANCZOS4)\n",
    "                \n",
    "                #Print update\n",
    "                print(f'      Correction applied for {camera_model} with {lens_model}.')\n",
    "                \n",
    "            except Exception:\n",
    "                \n",
    "                print(Exception)\n",
    "                \n",
    "                #Print update\n",
    "                print(f'      Correction failed. Invalid camera or lens inputs.')\n",
    "            \n",
    "        elif correct_distortion_mode == 'camera_calibration':     #Uses an existing calibration file from calibrate_camera utility\n",
    "            \n",
    "            x=y\n",
    "            \n",
    "        else:\n",
    "            print('      Distortion Correction Failed. Check inputs')\n",
    "            undistorted = image_original\n",
    "    \n",
    "    #Resize image to nominal size to increase computation speed(and adjust the anticipated aspect ratio as well)\n",
    "    \n",
    "    image = cv.resize(undistorted, (resize_cols, resize_rows))\n",
    "        \n",
    "    #NEED PREPROCESSING STEP WHICH ADJUSTS THE WHITE BALANCE SOMEHOW - WHEN IMAGING, WB should be constant\n",
    "    \n",
    "    #Convert to RGB and isolate channels\n",
    "    rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    rgb_min = np.amin(rgb, axis=2)\n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    red = rgb[:,:,0]\n",
    "    gre = rgb[:,:,1]\n",
    "    blu = rgb[:,:,2]\n",
    "    \n",
    "    #Calculate RGB statistics from the image \n",
    "    red_mean = np.mean(red)\n",
    "    red_hist = cv.calcHist([rgb], [0], None, [256], [0, 256])\n",
    "    gre_mean = np.mean(gre)\n",
    "    gre_hist = cv.calcHist([gre], [0], None, [256], [0, 256])\n",
    "    blu_mean = np.mean(blu)\n",
    "    blu_hist = cv.calcHist([blu], [0], None, [256], [0, 256])\n",
    "    print(f'   Image Statistics:')\n",
    "    print(f'      RGB Means: red = {red_mean:.2f};'\\\n",
    "          f' blue = {blu_mean:.2f}; green = {gre_mean:.2f}')\n",
    "    \n",
    "    \n",
    "    #Convert to HSV and isolate channels\n",
    "    hsv = cv.cvtColor(rgb, cv.COLOR_RGB2HSV)\n",
    "    hue = hsv[:,:,0]\n",
    "    sat = hsv[:,:,1]\n",
    "    val = hsv[:,:,2]\n",
    "    \n",
    "    #Calculate HSV statistics from the image\n",
    "    #hue = hue.astype(np.float64)\n",
    "    #hue[hue < 48] = hue + 48\n",
    "    hue_mean = np.mean(hue)\n",
    "    hue_hist = cv.calcHist([hue], [0], None, [256], [0, 256])\n",
    "    sat_mean = np.mean(sat)\n",
    "    sat_hist = cv.calcHist([sat], [0], None, [256], [0, 256])\n",
    "    val_mean = np.mean(val)\n",
    "    val_hist = cv.calcHist([val], [0], None, [256], [0, 256])\n",
    "    print(f'      HSV Means: hue = {hue_mean:.2f};'\\\n",
    "          f' saturation = {sat_mean:.2f}; value = {val_mean:.2f}')\n",
    "\n",
    "    #Detect if image is particularly dark \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Histogram Equalization\n",
    "    if equalize_hist and (equalize_method == 'adaptive'):\n",
    "        clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(9,9))\n",
    "        rgb_min = clahe.apply(rgb_min)\n",
    "        gray = clahe.apply(gray)\n",
    "        hue = clahe.apply(hue)\n",
    "    elif equalize_hist and (equalize_method == 'global'):\n",
    "        rgb_min = cv.equalizeHist(rgb_min)\n",
    "        gray = cv.equalizeHist(gray)\n",
    "        hue = cv.equalizeHist(hue)\n",
    "    \n",
    "    \n",
    "    #Iteratively refine detected edges in the images\n",
    "    edges, edge_outputs = segment.edgeDetection(rgb, rgb_min, gray, hue, image_pixels, debug=debug)\n",
    "    rgb_min_smooth = edge_outputs['rgb_min_smooth']\n",
    "    gray_smooth = edge_outputs['gray_smooth']\n",
    "    edges_rgb_min = edge_outputs['edges_rgb_min']\n",
    "    edges_gray = edge_outputs['edges_gray']\n",
    "    edges_hue = edge_outputs['edges_hue']\n",
    "    \n",
    "    #Detect prominent lines\n",
    "    print('   Line Detection:')\n",
    "    max_std = 1                                     #STD cutoff for line deviation\n",
    "    min_line_length = 150\n",
    "    max_line_gap = 10\n",
    "    hough_threshold = 100\n",
    "    hough_theta = np.pi/1080\n",
    "    hough_rho = 1\n",
    "    line_it = 0\n",
    "    line_repeat = True\n",
    "    sufficient_lines = False\n",
    "    while line_repeat & (line_it < 10):\n",
    "    \n",
    "        #Calculate lines with specified parameters\n",
    "        lines, line_points, line_points_edge, line_angles = segment.lineDetection(edges, hough_rho, hough_theta, \\\n",
    "                                                                                  hough_threshold, min_line_length,\\\n",
    "                                                                                  max_line_gap, resize_rows, resize_cols, \\\n",
    "                                                                                  debug=debug)\n",
    "        \n",
    "        #Filter lines \n",
    "        vert_inds, vert_lines, vert_angles, hori_inds, hori_lines, hori_angles, reject_inds, reject_lines, line_outputs \\\n",
    "            = segment.filterLines(lines, line_points, line_angles, hough_theta, debug = True)\n",
    "        \n",
    "        #Extract additional outputs\n",
    "        vert_angles_mean = line_outputs['vert_angles_mean']\n",
    "        vert_angles_std = line_outputs['vert_angles_std']\n",
    "        hori_angles_mean = line_outputs['hori_angles_mean']\n",
    "        hori_angles_std = line_outputs['hori_angles_std']\n",
    "        \n",
    "        #Determine vanishing points\n",
    "        vert_vanish_pt = line_outputs['vert_vanish_pt']\n",
    "        vert_vanish_xs = line_outputs['vert_vanish_xs']   \n",
    "        vert_vanish_ys = line_outputs['vert_vanish_ys']\n",
    "        hori_vanish_xs = []\n",
    "        hori_vanish_ys = []\n",
    "        \n",
    "        #Count number of final lines\n",
    "        num_lines = len(lines)\n",
    "        num_hori_lines = len(hori_lines)\n",
    "        num_vert_lines = len(vert_lines)\n",
    "        num_lines_filtered = num_lines -(num_hori_lines + num_vert_lines)\n",
    "        \n",
    "        #Determine if the line detection procedure should be repeated and strengthen or weaken parameters to achieve this\n",
    "        max_ct = 250\n",
    "        min_ct = 2      \n",
    "        if (num_vert_lines < min_ct) or (num_hori_lines < min_ct):\n",
    "            min_line_length *= 0.8 \n",
    "            max_line_gap *= 1.2 \n",
    "            max_std *= 1.1\n",
    "        elif (num_vert_lines > max_ct) or (num_hori_lines > max_ct):\n",
    "            min_line_length = 1.2 * min_line_length\n",
    "            max_line_gap = 0.8 * max_line_gap\n",
    "            max_std *= 0.9\n",
    "        else:\n",
    "            line_repeat = False\n",
    "            sufficient_lines = True\n",
    "            \n",
    "        #Output update\n",
    "        print(f'      ({line_it}): {num_lines} Lines Detected - {num_lines_filtered} Filtered - '\\\n",
    "              f'{num_hori_lines} Horizontal ({hori_angles_mean:.2f} +- {hori_angles_std:.2f} deg.)',\\\n",
    "              f'- {num_vert_lines} Vertical ({vert_angles_mean:.2f} +- {vert_angles_std:.2f} deg.)')\n",
    "        \n",
    "        #Iterate iteration counter\n",
    "        line_it = line_it + 1\n",
    "        \n",
    "        #Failure update\n",
    "        if line_repeat and (line_it == 10):\n",
    "            print(f'      ({line_it}): Line Detection Failed - Image Rejected')\n",
    "        \n",
    "\n",
    "    #Plot lines on the image\n",
    "    if debug:\n",
    "        gray_bgr = cv.cvtColor(gray_smooth, cv.COLOR_GRAY2BGR)\n",
    "        gray_bgr = segment.plotLines(gray_bgr, vert_lines, hori_lines, reject_lines)\n",
    "        gray_bgr_extended = cv.cvtColor(gray_smooth, cv.COLOR_GRAY2BGR)\n",
    "        gray_bgr_extended = segment.plotLines(gray, None, None, None, all_lines = line_points_edge)\n",
    "    \n",
    "    \n",
    "    #Plot vanishing points and perspective lines\n",
    "    #if debug:\n",
    "    #    gray_vanish_pts = gray_bgr\n",
    "    #    for v in range(0,len(vert_vanish_xs)):\n",
    "    #        if not (math.isnan(vert_vanish_xs[v])) and not (math.isnan(vert_vanish_ys[v])):\n",
    "    #            cv.circle(gray_vanish_pts, (int(vert_vanish_xs[v]), int(vert_vanish_ys[v])), 1, (0,128,255), thickness=-1)\n",
    "    #    for h in range(0,len(hori_vanish_xs)):\n",
    "    #        if not (math.isnan(hori_vanish_xs[h])) and not (math.isnan(hori_vanish_ys[h])):\n",
    "    #            cv.circle(gray_vanish_pts, (int(hori_vanish_xs[h]), int(hori_vanish_ys[h])), 1, (0,255,128), thickness=-1)\n",
    "            \n",
    "    #Select 4 representative lines - 2 Horizontal and 2 Vertical\n",
    "    #vert_lines_sort = np.argsort(vert_angles)\n",
    "    #vert_lines = vert_lines[vert_lines_sort]\n",
    "    #hori_lines_sort = np.argsort(hori_angles)\n",
    "    #hori_lines = hori_lines[hori_lines_sort]\n",
    "\n",
    "    #PASTE HERE\n",
    "    \n",
    "    #Calculate mean projective transform\n",
    "    if sufficient_lines:\n",
    "        print('   Projective Transform:')\n",
    "        transed, proj_trans, rot_ang, gray_sample_lines, gray_sample_box = segment.projectiveTransform(image_original, lines,\\\n",
    "                                                                                                   vert_inds, hori_inds,\\\n",
    "                                                                                                   gray_smooth, resize_rows,\\\n",
    "                                                                                                   image_scalar, hough_theta)\n",
    "\n",
    "        #Save image\n",
    "        transed = cv.cvtColor(transed, cv.COLOR_BGR2RGB)\n",
    "        output_path = os.path.join(prelim_output_dir, image_root + '_output' + images_ext)\n",
    "        try:\n",
    "            cv.imwrite(output_path, cv.cvtColor(transed, cv.COLOR_BGR2RGB))\n",
    "        except OSError:\n",
    "            os.mkdir(prelim_output_dir)\n",
    "            cv.imwrite(output_path, cv.cvtColor(transed, cv.COLOR_BGR2RGB))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Log end time and calculate total execution time\n",
    "    time_end = time.time()\n",
    "    time_execute = time_end - time_start\n",
    "    print(f'   Processing time: {time_execute:0.4f} s')\n",
    "    \n",
    "    #Generate debug plots\n",
    "    if debug:\n",
    "        generateDebugPlots()\n",
    "        \n",
    "    #Iteration counter    \n",
    "    image_it += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Based Module Perspective Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctModulePerspective(module_rgb, module_root, debug_dir=None, debug=True):\n",
    "    \n",
    "    #Create debug figure \n",
    "    if debug:\n",
    "        module_fig = plt.figure(num=f'Module Perspective Correction Debug', tight_layout=True,figsize=[18, 9.5])\n",
    "        gs = gridspec.GridSpec(2,3)\n",
    "        mng = plt.get_current_fig_manager()\n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "    #Alternative color space representations\n",
    "    module_bgr = cv.cvtColor(module_rgb, cv.COLOR_RGB2BGR)\n",
    "    module_gray = cv.cvtColor(module_bgr, cv.COLOR_BGR2GRAY)\n",
    "    module_rgb_min = np.amin(module_rgb, axis=2)\n",
    "    module_hsv = cv.cvtColor(module_bgr, cv.COLOR_BGR2HSV)\n",
    "    module_hue = module_hsv[:,:,0]\n",
    "    if debug:\n",
    "        axo = module_fig.add_subplot(gs[0,0])\n",
    "        plt.imshow(module_gray)\n",
    "        plt.title('Module Grayscale')\n",
    "        output_name = module_root + '_crop_initial' + images_ext\n",
    "        output_path = os.path.join(debug_dir, output_name)\n",
    "        cv.imwrite(output_path, module_rgb)\n",
    "    \n",
    "    #Calculate image dimensions\n",
    "    module_rows, module_cols, module_channels = module_bgr.shape\n",
    "    module_pixels = module_rows * module_cols\n",
    "    module_min_dim = np.min([module_rows, module_cols])\n",
    "    print(f'      Image Size is {module_rows} x {module_cols} ({module_pixels} px.)')\n",
    "    \n",
    "    #Detect Frame Outline\n",
    "    #detectFrameOutline(module_rgb)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Define edge detection parameters\n",
    "    edge_params = dict()\n",
    "    edge_params['gauss_size'] = (49,49)\n",
    "    edge_params['gauss_std'] = 3\n",
    "    edge_params['canny_thresh_min'] = 150\n",
    "    edge_params['canny_thresh_max'] = 220\n",
    "    edge_params['edge_ratio_goal'] = 0.1\n",
    "    edge_params['edge_ratio_range'] = (0.01, 0.20)\n",
    "    \n",
    "    #Define line detection parameters\n",
    "    max_std = 1                                     #STD cutoff for line deviation\n",
    "    min_line_length = int(0.5 * module_min_dim)\n",
    "    max_line_gap = int(0.33 * min_line_length)\n",
    "    hough_threshold = int(0.5 * min_line_length)\n",
    "    hough_theta = np.pi/1080\n",
    "    hough_rho = 1\n",
    "    line_it = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Detect lines in the original image\n",
    "    line_it = 0\n",
    "    line_repeat = True\n",
    "    print(f'\\n      Line Detection/Selection in Original Image:\\n')\n",
    "    while line_repeat & (line_it < 10):\n",
    "        \n",
    "        #Print update\n",
    "        #print(f'\\n      Iteration {line_it}:')\n",
    "        \n",
    "        #Detect edges\n",
    "        module_gray = cv.cvtColor(module_rgb.copy(), cv.COLOR_RGB2GRAY)\n",
    "        module_edges, module_edge_outputs = segment.edgeDetection(module_rgb.copy(), module_rgb_min, module_gray.copy(), module_hue, module_pixels,remove_total_black=True, params=edge_params, debug=False)\n",
    "        module_edge_its = module_edge_outputs['iterations']\n",
    "        module_edge_percent = module_edge_outputs['edge_percent']\n",
    "        module_thresh_low = module_edge_outputs['thresh_low']\n",
    "        module_thresh_high = module_edge_outputs['thresh_high']\n",
    "        module_total_black = module_edge_outputs['total_black']\n",
    "        print(f'        ({line_it}): Edge detection: {module_edge_its} iterations - Ratio = {module_edge_percent:.2f}% - Thresholds = '\\\n",
    "              f'({module_thresh_low}, {module_thresh_high})')\n",
    "        \n",
    "        #Detect lines\n",
    "        lines, line_points, line_points_edge, line_angles = segment.lineDetection(module_edges, hough_rho, hough_theta, \\\n",
    "                                                                                  hough_threshold, min_line_length,\\\n",
    "                                                                                  max_line_gap, module_rows, module_cols, \\\n",
    "                                                                                  debug=debug)\n",
    "        #Filter lines \n",
    "        vert_inds, vert_lines, vert_angles, hori_inds, hori_lines, hori_angles, reject_inds, reject_lines, line_outputs \\\n",
    "            = segment.filterLines(lines, line_points, line_angles, hough_theta, vert_select_mode='histogram', hori_select_ct=4,\\\n",
    "                                  vert_select_ct=4, debug = True)\n",
    "        \n",
    "        #Pull line statistics\n",
    "        vert_lines_stats = {'angles': line_outputs['vert_angles_all'],'angles_mean': line_outputs['vert_angles_mean'], \\\n",
    "                            'angles_std': line_outputs['vert_angles_std']}\n",
    "        hori_lines_stats = {'angles': line_outputs['hori_angles_all'],'angles_mean': line_outputs['hori_angles_mean'], \\\n",
    "                            'angles_std': line_outputs['hori_angles_std']}\n",
    "        \n",
    "        #Pull mean angles and stds\n",
    "        vert_angles_mean = vert_lines_stats['angles_mean']\n",
    "        vert_angles_std = vert_lines_stats['angles_std']\n",
    "        hori_angles_mean = hori_lines_stats['angles_mean']\n",
    "        hori_angles_std = hori_lines_stats['angles_std']  \n",
    "    \n",
    "        #Count number of final lines\n",
    "        num_lines = len(lines)\n",
    "        num_hori_lines = len(hori_lines_stats['angles'])\n",
    "        num_vert_lines = len(vert_lines_stats['angles'])\n",
    "        num_hori_lines_chosen = len(hori_lines)\n",
    "        num_vert_lines_chosen = len(vert_lines)\n",
    "        num_lines_filtered = num_lines - (num_hori_lines + num_vert_lines)\n",
    "        \n",
    "        #Print update about all lines detected (not exclusively filtered lines)\n",
    "        print(f'        ({line_it}): Line Detection: {num_lines} Detected - '\\\n",
    "              f'{num_hori_lines} Horizontal ({hori_angles_mean:.2f} +- {hori_angles_std:.2f} deg.)',\\\n",
    "              f'- {num_vert_lines} Vertical ({vert_angles_mean:.2f} +- {vert_angles_std:.2f} deg.)')\n",
    "        \n",
    "        #Print update about line selection\n",
    "        print(f'        ({line_it}): Line Selection: {num_hori_lines_chosen} Horizontal - {num_vert_lines_chosen} Vertical\\n')\n",
    "        \n",
    "        #Determine if there are at least two lines in each direction after filtration\n",
    "        sufficient_lines = (num_hori_lines_chosen >= 2) & (num_vert_lines_chosen >= 2)    #looks only at filtered lines\n",
    "        \n",
    "        #Determine if the line detection is of a sufficient quality \n",
    "        acceptable_lines = True\n",
    "        \n",
    "        #Determine if line detection/selection needs to be repeated\n",
    "        line_it += 1\n",
    "        if sufficient_lines and acceptable_lines:\n",
    "            line_repeat = False\n",
    "        else:\n",
    "            \n",
    "            #Update edge detection and line parameters\n",
    "            if (num_hori_lines < 3) or (num_vert_lines < 3):\n",
    "                min_line_length = int(0.8 * min_line_length)\n",
    "                max_line_gap = int(0.33 * min_line_length)\n",
    "                hough_threshold = int(0.5 * min_line_length)\n",
    "            elif (num_hori_lines > 100) or (num_vert_lines > 100):\n",
    "                min_line_length = int(1.1 * min_line_length)\n",
    "                max_line_gap = int(0.33 * min_line_length)\n",
    "                hough_threshold = int(0.5 * min_line_length)\n",
    "            \n",
    "\n",
    "    #Define perspective correction parameters\n",
    "    test_std = 0.5\n",
    "      \n",
    "        \n",
    "    #Allocate debug lists\n",
    "    module_transeds = []\n",
    "    module_boxes = []\n",
    "    module_liness = []\n",
    "    module_edgess = []\n",
    "    module_transeds.append(module_rgb.copy())   \n",
    "    module_liness.append(segment.plotLines(module_rgb.copy(), vert_lines, hori_lines, reject_lines))\n",
    "    module_edgess.append(module_edges)\n",
    "            \n",
    "    #Allocate storage lists for paralleity indicators    \n",
    "    hori_vert_angles = []\n",
    "    hori_vert_angle_tests = []\n",
    "    hori_tests = []\n",
    "    vert_tests = []\n",
    "    vert_std_tests = []\n",
    "    hori_std_tests = []\n",
    "    proj_transs = []\n",
    "    parallelities = []\n",
    "        \n",
    "    #Perspective Correction Selection \n",
    "    perspec_it = 0\n",
    "    correct_perspective = True\n",
    "    if sufficient_lines:\n",
    "        \n",
    "        print('      Perspective Correction Testing:\\n')\n",
    "        for h1 in range(0, num_hori_lines_chosen):\n",
    "            for h2 in range(h1+1, num_hori_lines_chosen):\n",
    "                for v1 in range(0, num_vert_lines_chosen):\n",
    "                    for v2 in range(v1+1, num_vert_lines_chosen):\n",
    "        \n",
    "                        #Only go through the logic if the image is not acceptable\n",
    "                        if correct_perspective:\n",
    "\n",
    "                            #Define indicies\n",
    "                            input_hori_inds = [hori_inds[h1], hori_inds[h2]]\n",
    "                            input_vert_inds = [vert_inds[v1], vert_inds[v2]]            \n",
    "                            #print(input_vert_inds), print(input_hori_inds)\n",
    "\n",
    "                            #Determine if lines meet parallelity guidelines\n",
    "                            hori_vert_angle = np.abs(vert_angles_mean - hori_angles_mean)\n",
    "                            hori_vert_angle_test = (hori_vert_angle > 88) and (hori_vert_angle < 92)\n",
    "                            hori_test = (hori_angles_mean >= -1) and (hori_angles_mean <= 1)\n",
    "                            vert_test = (vert_angles_mean >= 89) and (vert_angles_mean <= 91)\n",
    "                            vert_std_test = (vert_angles_std < test_std)\n",
    "                            hori_std_test = (hori_angles_std < test_std)\n",
    "                            if hori_vert_angle_test and hori_test and vert_test and vert_std_test and hori_std_test:\n",
    "                                correct_perspective = False\n",
    "                                \n",
    "                            #Define and store paralleity\n",
    "                            if hori_test and vert_test and hori_vert_angle_test:\n",
    "                                parallelity = vert_angles_std + hori_angles_std\n",
    "                            else:\n",
    "                                parallelity = 1000\n",
    "                            parallelities.append(parallelity)\n",
    "                            \n",
    "                            \n",
    "\n",
    "                            #Print parallelity update \n",
    "                            print(f'        ({perspec_it}): Horizontal = {hori_test}; Vertical = {vert_test}; Vert. Parallel = {vert_std_test}; Hori. Parallel = {hori_std_test}; Right Angles = {hori_vert_angle_test}')\n",
    "\n",
    "                            #Log logical tests\n",
    "                            hori_vert_angles.append(hori_vert_angle)\n",
    "                            hori_vert_angle_tests.append(hori_vert_angle_test)\n",
    "                            hori_tests.append(hori_test)\n",
    "                            vert_tests.append(vert_test)\n",
    "                            vert_std_tests.append(vert_std_test)\n",
    "                            hori_std_tests.append(hori_std_test)\n",
    "\n",
    "                            #Perspective correction - if the module isn't already acceptably rectangular\n",
    "                            if correct_perspective:\n",
    "\n",
    "                                #Iterate through line combinations\n",
    "                                module_transed, proj_trans, rot_ang, module_lines, module_box = segment.projectiveTransform(module_rgb.copy(), lines,\\\n",
    "                                                                                                                       input_vert_inds, input_hori_inds,\\\n",
    "                                                                                                                       module_gray.copy(), module_rows,\\\n",
    "                                                                                                                       1, hough_theta)\n",
    "                                #Redefine module_rgb and store proj transform\n",
    "                                test_module_rgb = module_transed.copy()\n",
    "                                proj_transs.append(proj_trans)\n",
    "\n",
    "                                #Log transformed images\n",
    "                                if debug:\n",
    "                                    module_boxes.append(module_box)\n",
    "                                    module_transeds.append(module_rgb)\n",
    "\n",
    "                                #Detect Edges in the new image \n",
    "                                test_module_gray = cv.cvtColor(test_module_rgb.copy(), cv.COLOR_RGB2GRAY)\n",
    "                                test_module_edges, test_module_edge_outputs = segment.edgeDetection(test_module_rgb.copy(), module_rgb_min, test_module_gray.copy(), module_hue, module_pixels,remove_total_black=True, params=edge_params, debug=False)\n",
    "\n",
    "                                #Detect Lines \n",
    "                                test_lines, test_line_points, test_line_points_edge, test_line_angles = segment.lineDetection(test_module_edges, hough_rho, hough_theta, \\\n",
    "                                                                                          hough_threshold, min_line_length,\\\n",
    "                                                                                          max_line_gap, module_rows, module_cols, \\\n",
    "                                                                                          debug=debug)\n",
    "                                #Filter lines \n",
    "                                test_vert_inds, test_vert_lines, test_vert_angles, test_hori_inds, test_hori_lines, test_hori_angles, test_reject_inds,\\\n",
    "                                test_reject_lines, test_line_outputs = segment.filterLines(test_lines, test_line_points, test_line_angles, hough_theta,\\\n",
    "                                                                                           vert_select_mode='histogram', hori_select_ct=4,\\\n",
    "                                                                                           vert_select_ct=4, debug = True)\n",
    "\n",
    "                                #Pull line statistics\n",
    "                                vert_lines_stats = {'angles': test_line_outputs['vert_angles_all'],'angles_mean': test_line_outputs['vert_angles_mean'], \\\n",
    "                                                    'angles_std': test_line_outputs['vert_angles_std']}\n",
    "                                hori_lines_stats = {'angles': test_line_outputs['hori_angles_all'],'angles_mean': test_line_outputs['hori_angles_mean'], \\\n",
    "                                                    'angles_std': test_line_outputs['hori_angles_std']}\n",
    "\n",
    "                                #Pull mean angles and stds\n",
    "                                vert_angles_mean = vert_lines_stats['angles_mean']\n",
    "                                vert_angles_std = vert_lines_stats['angles_std']\n",
    "                                hori_angles_mean = hori_lines_stats['angles_mean']\n",
    "                                hori_angles_std = hori_lines_stats['angles_std']  \n",
    "\n",
    "                                #Count number of final lines\n",
    "                                num_lines = len(lines)\n",
    "                                num_hori_lines = len(hori_lines_stats['angles'])\n",
    "                                num_vert_lines = len(vert_lines_stats['angles'])\n",
    "                                num_hori_lines_chosen = len(hori_lines)\n",
    "                                num_vert_lines_chosen = len(vert_lines)\n",
    "                                num_lines_filtered = num_lines -(num_hori_lines + num_vert_lines)\n",
    "\n",
    "                                #Print update about all lines detected (not exclusively filtered lines)\n",
    "                                print(f'        ({perspec_it}): Line Detection: {num_lines} Detected - '\\\n",
    "                                      f'{num_hori_lines} Horizontal ({hori_angles_mean:.2f} +- {hori_angles_std:.2f} deg.)',\\\n",
    "                                      f'- {num_vert_lines} Vertical ({vert_angles_mean:.2f} +- {vert_angles_std:.2f} deg.)\\n')\n",
    "\n",
    "\n",
    "\n",
    "                                #Update iteration counter\n",
    "                                perspec_it += 1\n",
    "                        \n",
    "            \n",
    "                                #Log images\n",
    "                                if debug:\n",
    "                                    module_edgess.append(test_module_edges)\n",
    "                                    module_liness.append(segment.plotLines(test_module_rgb.copy(), test_vert_lines, test_hori_lines, test_reject_lines))\n",
    "        \n",
    "    else:\n",
    "        print(f'        -Insufficient lines remain after filtering. Image likely unacceptable.')\n",
    "        line_repeat = False\n",
    "\n",
    "    \n",
    "\n",
    "    #Select best projective transform if none meet initial guidelines\n",
    "    if correct_perspective and sufficient_lines:\n",
    "        \n",
    "        #Select best projective transform (which produces most acceptable lines)\n",
    "        most_parallel = np.argmin(parallelities)\n",
    "        module_rgb = module_transeds[most_parallel]\n",
    "        \n",
    "    elif (perspec_it > 0):\n",
    "        module_rgb = test_module_rgb\n",
    "        \n",
    "    else:\n",
    "        module_rgb = module_rgb     #Just stating that it passes through\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    #Plot lines in image and display\n",
    "    if debug:\n",
    "        \n",
    "        #Define figures \n",
    "        perspec_fig = plt.figure(num=f'Perspective Correction Progression', tight_layout=True,figsize=[18, 9.5])\n",
    "        lines_fig = plt.figure(num=f'Line Detection Progression', tight_layout=True,figsize=[18, 9.5])\n",
    "        boxes_fig = plt.figure(num=f'Perspective Correction Boxes Progression', tight_layout=True,figsize=[18, 9.5])\n",
    "        edges_fig = plt.figure(num=f'Edge Detection Progression', tight_layout=True,figsize=[18, 9.5])\n",
    "        \n",
    "        #Define subplot params\n",
    "        sub_rows = 3\n",
    "        sub_cols = 10\n",
    "        sub_ct = sub_rows * sub_cols\n",
    "        \n",
    "        #Iterate through images and plot the perspective correction refinement images\n",
    "        for i in range(0, len(module_transeds)):\n",
    "            \n",
    "            if i < sub_ct:\n",
    "                \n",
    "                #Perspective Correction\n",
    "                plt.figure('Perspective Correction Progression')\n",
    "                ax1 = plt.subplot(sub_rows,sub_cols,i+1)\n",
    "                plt.imshow(module_transeds[i])\n",
    "                plt.title(f'Iteration {i}')\n",
    "\n",
    "                #Perspective Correction Boxes\n",
    "                if i < (len(module_transeds)):\n",
    "                    plt.figure('Perspective Correction Boxes Progression')\n",
    "                    ax1 = plt.subplot(sub_rows,sub_cols,i+1)\n",
    "                    #plt.imshow(module_boxes[i])\n",
    "                    plt.title(f'Iteration {i}')\n",
    "            \n",
    "        for i in range(0, len(module_liness)):\n",
    "        \n",
    "            if i < sub_ct:\n",
    "                \n",
    "                #Edge Detection\n",
    "                plt.figure('Edge Detection Progression')\n",
    "                ax1 = plt.subplot(sub_rows,sub_cols,i+1)\n",
    "                plt.imshow(module_edgess[i])\n",
    "                plt.title(f'Iteration {i}')\n",
    "\n",
    "                #Line Detection\n",
    "                plt.figure('Line Detection Progression')\n",
    "                ax1 = plt.subplot(sub_rows,sub_cols,i+1)\n",
    "                plt.imshow(module_liness[i])\n",
    "                plt.title(f'Iteration {i}') \n",
    "        \n",
    "        #Change figure\n",
    "        plt.figure('Module Perspective Correction Debug')\n",
    "        \n",
    "        #Plot final edge detection image\n",
    "        axe = module_fig.add_subplot(gs[0,1])\n",
    "        plt.imshow(module_edges)\n",
    "        plt.title('Module Edges')\n",
    "        output_name = module_root + '_edges' + images_ext\n",
    "        output_path = os.path.join(debug_dir, output_name)\n",
    "        #cv.imwrite(output_path, module_edges)\n",
    "        \n",
    "        #Plot segments detected\n",
    "        plt.figure(\"Module Perspective Correction Debug\")\n",
    "        lines_bgr = segment.plotLines(module_bgr.copy(), vert_lines, hori_lines, reject_lines)\n",
    "        axls = module_fig.add_subplot(gs[1,0])\n",
    "        plt.imshow(lines_bgr)\n",
    "        plt.title('Detected line segments')\n",
    "        output_name = module_root + '_lines_segments' + images_ext\n",
    "        output_path = os.path.join(debug_dir, output_name)\n",
    "        #cv.imwrite(output_path, cv.cvtColor(lines_bgr, cv.COLOR_BGR2RGB))\n",
    "        \n",
    "        #Plot the segments extended to the edges\n",
    "        lines_bgr_extended = segment.plotLines(module_bgr.copy(), None, None, None, all_lines = line_points_edge)\n",
    "        axlse = module_fig.add_subplot(gs[1,1])\n",
    "        plt.imshow(lines_bgr_extended)\n",
    "        plt.title('Extended line segments')\n",
    "        output_name = module_root + '_lines_extended' + images_ext\n",
    "        output_path = os.path.join(debug_dir, output_name)\n",
    "        #cv.imwrite(output_path, cv.cvtColor(lines_bgr_extended, cv.COLOR_BGR2RGB))\n",
    "        \n",
    "        #Plot detected total black regions in input image\n",
    "        axblk = module_fig.add_subplot(gs[1,2])\n",
    "        plt.imshow(module_total_black)\n",
    "        plt.title('Total Black Regions')\n",
    "        \n",
    "        \n",
    "    \n",
    "        #Save all figures \n",
    "        output_path = os.path.join(module_debug_output_dir, module_root + '_perspec_debug' + images_ext)\n",
    "        perspec_fig.savefig(output_path)\n",
    "        output_path = os.path.join(module_debug_output_dir, module_root + '_perspec_boxes_debug' + images_ext)\n",
    "        boxes_fig.savefig(output_path)\n",
    "        output_path = os.path.join(module_debug_output_dir, module_root + '_edge_debug' + images_ext)\n",
    "        edges_fig.savefig(output_path)\n",
    "        output_path = os.path.join(module_debug_output_dir, module_root + '_lines_debug' + images_ext)\n",
    "        lines_fig.savefig(output_path)\n",
    "        output_path = os.path.join(module_debug_output_dir, module_root + '_line_debug' + images_ext)\n",
    "        module_fig.savefig(output_path)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Save final image\n",
    "    output_name = module_root + '_crop_final' + images_ext\n",
    "    output_path = os.path.join(debug_dir, output_name)\n",
    "    cv.imwrite(output_path, module_rgb)\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.close('all')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binarization - Apply Substantial Blur\n",
    "\n",
    "def moduleBinarization(debug=True):\n",
    "\n",
    "    #Apply a blur\n",
    "    gauss_std = 1.5\n",
    "    module_bgr_blur = cv.GaussianBlur(module_bgr, (25, 25), 1)    \n",
    "    \n",
    "    #Binarization - Color space representations\n",
    "    module_hsv_blur = cv.cvtColor(module_bgr_blur, cv.COLOR_BGR2HSV)\n",
    "    module_hue_blur = module_hsv_blur[:,:,0]\n",
    "    module_sat_blur = module_hsv_blur[:,:,1]\n",
    "    module_val_blur = module_hsv_blur[:,:,2]\n",
    "    module_blue_blur = module_bgr_blur[:,:,0]\n",
    "    module_green_blur = module_bgr_blur[:,:,1]\n",
    "    module_gray_blur = cv.cvtColor(module_bgr_blur, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #Binarization - Roseplot and Histogram generation\n",
    "    hist_blue = cv.calcHist([module_blue_blur], [0], None, [256], [0,256])\n",
    "    hist_green = cv.calcHist([module_green_blur], [0], None, [256], [0,256])\n",
    "    hist_gray = cv.calcHist([module_gray_blur], [0], None, [256], [0,256])\n",
    "    rose_hue = cv.calcHist([module_hue_blur], [0], None, [180], [0,180])\n",
    "    hist_sat = cv.calcHist([module_sat_blur], [0], None, [256], [0,256])\n",
    "    hist_val = cv.calcHist([module_val_blur], [0], None, [256], [0,256])\n",
    "    \n",
    "    \n",
    "    #Binarization thresholding - OTSU\n",
    "    thresh_blue, binary_blue = cv.threshold(module_blue_blur, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "    thresh_green, binary_green = cv.threshold(module_green_blur, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "    thresh_gray, binary_gray = cv.threshold(module_gray_blur, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "    thresh_sat, binary_sat = cv.threshold(module_sat_blur, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "    thresh_val, binary_val = cv.threshold(module_val_blur, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "    \n",
    "    #Binary thresholding - Adaptive\n",
    "    block_size = 17\n",
    "    binary_blue_adp = cv.adaptiveThreshold(module_blue_blur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, block_size, 2)\n",
    "    binary_green_adp = cv.adaptiveThreshold(module_green_blur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, block_size, 2)\n",
    "    binary_gray_adp = cv.adaptiveThreshold(module_gray_blur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, block_size, 2)\n",
    "    binary_sat_adp = cv.adaptiveThreshold(module_sat_blur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, block_size, 2)\n",
    "    binary_val_adp = cv.adaptiveThreshold(module_val_blur, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, block_size, 2)\n",
    "    \n",
    "    #Binarization - Histogram outputs\n",
    "    if debug:\n",
    "        \n",
    "        #Create figure \n",
    "        hist_fig = plt.figure(num=f'Binarization Histogram Debug', tight_layout=True,figsize=[18, 9.5])\n",
    "        \n",
    "        #Plot histograms\n",
    "        ax_gray = plt.subplot(2,3,1)\n",
    "        plt.plot(hist_gray)\n",
    "        plt.title('Grayscale Histogram')\n",
    "        \n",
    "        ax_blue = plt.subplot(2,3,2)\n",
    "        plt.plot(hist_blue)\n",
    "        plt.title('Blue Histogram')\n",
    "        \n",
    "        ax_green = plt.subplot(2,3,3)\n",
    "        plt.plot(hist_green)\n",
    "        plt.title('Green Histogram')\n",
    "        \n",
    "        #ax_hue = plt.subplot(2,3,4, projection='polar')\n",
    "        #plt.bar(np.linspace(0,360,num=181), rose_hue)\n",
    "        #plt.title('Grayscale Histogram')\n",
    "        \n",
    "        ax_sat = plt.subplot(2,3,5)\n",
    "        plt.plot(hist_sat)\n",
    "        plt.title('Saturation Histogram')\n",
    "        \n",
    "        ax_val = plt.subplot(2,3,6)\n",
    "        plt.plot(hist_val)\n",
    "        plt.title('Value Histogram')\n",
    "    \n",
    "    #Binarization - Thresholding outputs\n",
    "    if debug:\n",
    "        \n",
    "        #Create figure\n",
    "        binary_fig = plt.figure(num=f'Binarization Debug', tight_layout=True,figsize=[18, 9.5])\n",
    "     \n",
    "        #Show images\n",
    "        ax_gray = plt.subplot(3,4,1)\n",
    "        plt.imshow(binary_gray)\n",
    "        plt.title('Grayscale OTSU Global')\n",
    "    \n",
    "        ax_blue = plt.subplot(3,4,5)\n",
    "        plt.imshow(binary_blue)\n",
    "        plt.title('Blue OTSU Global')\n",
    "        \n",
    "        ax_green = plt.subplot(3,4,9)\n",
    "        plt.imshow(binary_green)\n",
    "        plt.title('Green OTSU Global')\n",
    "        \n",
    "        ax_gray = plt.subplot(3,4,2)\n",
    "        plt.imshow(binary_gray_adp)\n",
    "        plt.title('Grayscale Gauss Adaptive')\n",
    "    \n",
    "        ax_blue = plt.subplot(3,4,6)\n",
    "        plt.imshow(binary_blue_adp)\n",
    "        plt.title('Blue Gauss Adaptive')\n",
    "        \n",
    "        ax_green = plt.subplot(3,4,10)\n",
    "        plt.imshow(binary_green_adp)\n",
    "        plt.title('Green Gauss Adaptive')\n",
    "        \n",
    "        ax_sat = plt.subplot(3,4,7)\n",
    "        plt.imshow(binary_sat)\n",
    "        plt.title('Saturation OTSU Global')\n",
    "        \n",
    "        ax_val = plt.subplot(3,4,11)\n",
    "        plt.imshow(binary_val)\n",
    "        plt.title('Value OTSU Global')\n",
    "    \n",
    "        ax_sat_adp = plt.subplot(3,4,8)\n",
    "        plt.imshow(binary_sat_adp)\n",
    "        plt.title('Saturation Gauss Adaptive')\n",
    "        \n",
    "        ax_val_adp = plt.subplot(3,4,12)\n",
    "        plt.imshow(binary_val_adp)\n",
    "        plt.title('Value Gauss Adaptive')\n",
    "        \n",
    "        \n",
    "        \n",
    "    output_path = os.path.join(module_debug_output_dir, module_root + '_binary_debug' + images_ext)\n",
    "    binary_fig.savefig(output_path)\n",
    "    output_path = os.path.join(module_debug_output_dir, module_root + '_hist_debug' + images_ext)\n",
    "    hist_fig.savefig(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame Outline Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFrameOutline(rgb, debug=True):\n",
    "    \n",
    "    #Convert image to other representations\n",
    "    gray = cv.cvtColor(rgb, cv.COLOR_RGB2GRAY)\n",
    "    hsv = cv.cvtColor(rgb, cv.COLOR_RGB2HSV)\n",
    "    h = hsv[:,:,0]\n",
    "    s = hsv[:,:,1]\n",
    "    v = hsv[:,:,2]\n",
    "    r = rgb[:,:,0]\n",
    "    g = rgb[:,:,1]\n",
    "    b = rgb[:,:,2]\n",
    "    \n",
    "    #Apply gaussian filter\n",
    "    gray = cv.GaussianBlur(gray, (49, 49), 1)\n",
    "    \n",
    "    #Debug display all the color channels\n",
    "    if debug:\n",
    "        chan_fig = plt.figure(num=f'Frame Outline Detection Debug - Color Spaces', tight_layout=True,figsize=[18, 9.5])\n",
    "        plt.subplot(341), plt.imshow(rgb), plt.title('RGB')\n",
    "        plt.subplot(342), plt.imshow(r), plt.title('R')\n",
    "        plt.subplot(343), plt.imshow(g), plt.title('G')\n",
    "        plt.subplot(344), plt.imshow(b), plt.title('B')\n",
    "        plt.subplot(345), plt.imshow(hsv), plt.title('HSV')\n",
    "        plt.subplot(346), plt.imshow(h), plt.title('H')\n",
    "        plt.subplot(347), plt.imshow(s), plt.title('S')\n",
    "        plt.subplot(348), plt.imshow(v), plt.title('V')\n",
    "        plt.subplot(349), plt.imshow(gray), plt.title('Grayscale')\n",
    "        \n",
    "    \n",
    "    #Pull image size\n",
    "    rows, cols, channels = rgb.shape \n",
    "    if rows > cols:\n",
    "        max_dim = rows\n",
    "        min_dim = cols\n",
    "        portrait = True\n",
    "        orientation = 'vertically'\n",
    "    else:\n",
    "        max_dim = cols\n",
    "        min_dim = rows\n",
    "        portrait = False          \n",
    "        orientation = 'horizontally'\n",
    "\n",
    "    #Feedback\n",
    "    if debug:\n",
    "        print(f'       Module is oriented {orientation}.')\n",
    "        plt.figure()\n",
    "        plt.imshow(rgb)\n",
    "    \n",
    "       \n",
    "    #Define Segment indicies\n",
    "    max_dim_inds = np.linspace(0, max_dim, 4)   #three segments\n",
    "    min_dim_inds = np.linspace(0, min_dim, 3)   #two segments\n",
    "\n",
    "    print(min_dim_inds), print(max_dim_inds)\n",
    "    \n",
    "    #Divide segments\n",
    "    seg_fig = plt.figure(num=f'Frame Outline Detection Debug - Segments', tight_layout=True,figsize=[18, 9.5])\n",
    "    segments_gray = []\n",
    "    s = 0\n",
    "    for imin in range(0,2):\n",
    "        \n",
    "        for imax in range(0,3):\n",
    "            #Define indicies to pull each directions pixel indicies from\n",
    "            #imin = np.mod(s, 2)\n",
    "            #imax = np.mod(s, 3)\n",
    "            #Pull segment from image\n",
    "            if portrait:  \n",
    "                x1 = int(min_dim_inds[imin])\n",
    "                x2 = int(min_dim_inds[imin + 1])\n",
    "                y1 = int(max_dim_inds[imax])\n",
    "                y2 = int(max_dim_inds[imax + 1])\n",
    "                segment_gray = gray[x1:x2, y1:y2]\n",
    "                segments_gray.append(segment_gray)\n",
    "            else:\n",
    "                x1 = int(min_dim_inds[imin])\n",
    "                x2 = int(min_dim_inds[imin + 1])\n",
    "                y1 = int(max_dim_inds[imax])\n",
    "                y2 = int(max_dim_inds[imax + 1])\n",
    "                segment_gray = gray[x1:x2, y1:y2]\n",
    "                segments_gray.append(segment_gray)\n",
    "\n",
    "            #Display segment\n",
    "            if debug:\n",
    "                plt.figure('Frame Outline Detection Debug - Segments')\n",
    "                plt.subplot(2,3,s+1), plt.title(f'Segment {s}')\n",
    "                plt.imshow(segment_gray)\n",
    "\n",
    "            #Iterate through rows - calculate statistics\n",
    "            x_lines_gray = []\n",
    "            x_der1s_gray = []\n",
    "            x_der2s_gray = []\n",
    "            x_means_gray = []\n",
    "            x_mins_gray = []\n",
    "            x_maxs_gray = []\n",
    "            x_stds_gray = []\n",
    "            x_maxs_der1_gray = []\n",
    "            x_extrema_diffs_gray = []\n",
    "            for r in range(0, (x2-x1)):\n",
    "\n",
    "                #Pull data\n",
    "                line_gray = segment_gray[r, :]\n",
    "                der1_gray = np.diff(line_gray)\n",
    "                der2_gray = np.diff(der1_gray)\n",
    "\n",
    "                #Calculate statistics\n",
    "                x_means_gray.append(np.mean(line_gray))\n",
    "                x_mins_gray.append(np.min(line_gray))\n",
    "                x_maxs_gray.append(np.max(line_gray))\n",
    "                x_stds_gray.append(np.std(line_gray))\n",
    "                x_maxs_der1_gray.append(np.max(der1_gray))\n",
    "                x_extrema_diffs_gray.append(np.max(line_gray) - np.min(line_gray))\n",
    "\n",
    "                #Store lines\n",
    "                x_lines_gray.append(line_gray)\n",
    "                x_der1s_gray.append(der1_gray)\n",
    "                x_der2s_gray.append(der2_gray)\n",
    "\n",
    "\n",
    "            #Calculate row aggregate statistics  \n",
    "            x_mean_gray = np.mean(x_means_gray)\n",
    "            x_mean_std_gray = np.std(x_means_gray)\n",
    "            x_max_gray = np.mean(x_maxs_gray)\n",
    "            x_max_std_gray = np.std(x_maxs_gray)\n",
    "            x_extrema_diff_gray = np.mean(x_extrema_diffs_gray)\n",
    "            x_extrema_diff_std_gray = np.std(x_extrema_diffs_gray)\n",
    "\n",
    "            #Filter lines into two groups: foreground and background\n",
    "            x_mean_test = x_means_gray >=(x_mean_gray - 1 * x_mean_std_gray)\n",
    "            x_max_test = x_maxs_gray >= (x_max_gray - 1 * x_max_std_gray)\n",
    "            x_extrema_diff_test = x_extrema_diffs_gray >= (x_extrema_diff_gray - 0.5 * x_extrema_diff_std_gray)        \n",
    "            x_backgrnd_gray = np.where(np.invert(x_mean_test & x_max_test & x_extrema_diff_test))\n",
    "            x_foregrnd_gray = np.where(x_mean_test & x_max_test & x_extrema_diff_test) \n",
    "            x_backgrnd_lines_gray = [x_lines_gray[i] for i in x_backgrnd_gray[0]]\n",
    "            x_foregrnd_lines_gray = [x_lines_gray[i] for i in x_foregrnd_gray[0]]\n",
    "            print(x_foregrnd_gray)\n",
    "\n",
    "            #Iterate through columns - calculate statistics\n",
    "            y_lines_gray = []\n",
    "            y_der1s_gray = []\n",
    "            y_der2s_gray = []\n",
    "            y_means_gray = []\n",
    "            y_mins_gray = []\n",
    "            y_maxs_gray = []\n",
    "            y_stds_gray = []\n",
    "            y_maxs_der1_gray = []  \n",
    "            y_extrema_diffs_gray = []\n",
    "            for c in range(0, (y2-y1)):\n",
    "\n",
    "                #Pull data\n",
    "                line_gray = segment_gray[:, c]\n",
    "                der1_gray = np.diff(line_gray)\n",
    "                der2_gray = np.diff(der1_gray)\n",
    "\n",
    "                #Calculate statistics\n",
    "                y_means_gray.append(np.mean(line_gray))\n",
    "                y_mins_gray.append(np.min(line_gray))\n",
    "                y_maxs_gray.append(np.max(line_gray))\n",
    "                y_stds_gray.append(np.std(line_gray))\n",
    "                y_maxs_der1_gray.append(np.max(der1_gray))           \n",
    "                y_extrema_diffs_gray.append(np.max(line_gray) - np.min(line_gray))\n",
    "\n",
    "                #Store lines\n",
    "                y_lines_gray.append(line_gray)\n",
    "                y_der1s_gray.append(der1_gray)\n",
    "                y_der2s_gray.append(der2_gray)    \n",
    "\n",
    "\n",
    "            #Calculate row aggregate statistics  \n",
    "            y_mean_gray = np.mean(y_means_gray)\n",
    "            y_mean_std_gray = np.std(y_means_gray)\n",
    "            y_max_gray = np.mean(y_maxs_gray)\n",
    "            y_max_std_gray = np.std(y_maxs_gray)\n",
    "            y_extrema_diff_gray = np.mean(y_extrema_diffs_gray)\n",
    "            y_extrema_diff_std_gray = np.std(y_extrema_diffs_gray)\n",
    "\n",
    "            #Filter lines into two groups: foreground and background\n",
    "            y_mean_test = y_means_gray >=(y_mean_gray - 1 * y_mean_std_gray)\n",
    "            y_max_test = y_maxs_gray >= (y_max_gray - 1 * y_max_std_gray)\n",
    "            y_extrema_diff_test = y_extrema_diffs_gray >= (y_extrema_diff_gray - 0.5 * y_extrema_diff_std_gray)        \n",
    "            y_backgrnd_gray = np.where(np.invert(y_mean_test & y_max_test & y_extrema_diff_test))\n",
    "            y_foregrnd_gray = np.where(y_mean_test & y_max_test & y_extrema_diff_test) \n",
    "            y_backgrnd_lines_gray = [y_lines_gray[i] for i in y_backgrnd_gray[0]]\n",
    "            y_foregrnd_lines_gray = [y_lines_gray[i] for i in y_foregrnd_gray[0]]\n",
    "            #print(y_foregrnd_gray)\n",
    "\n",
    "            \n",
    "\n",
    "            #Debug figure \n",
    "            lines_fig = plt.figure(num=f'Frame Outline Detection Debug - Segment Lines {s}', tight_layout=True,figsize=[18, 9.5])\n",
    "            plt.subplot(121), plt.title('X Lines')\n",
    "            for b in range(0, len(x_backgrnd_lines_gray)):\n",
    "                plt.plot(x_backgrnd_lines_gray[b], 'r-', alpha=0.5)\n",
    "                \n",
    "                \n",
    "            for f in range(0, len(x_foregrnd_lines_gray)):\n",
    "                plt.plot(x_foregrnd_lines_gray[f], 'g-')\n",
    "                \n",
    "                \n",
    "            plt.subplot(122), plt.title('Y Lines')\n",
    "            for b in range(0, len(y_backgrnd_lines_gray)):\n",
    "                plt.plot(y_backgrnd_lines_gray[b], 'r-')\n",
    "                \n",
    "                \n",
    "            for f in range(0, len(y_foregrnd_lines_gray)):\n",
    "                plt.plot(y_foregrnd_lines_gray[f], 'g-')\n",
    "                \n",
    "                \n",
    "        \n",
    "            #Iterate segment counter\n",
    "            s += 1\n",
    "        \n",
    "    x=y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Detection with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module Detection Setup:\n",
      "   341 images found in directory meeting image spec.\n",
      "   Frozen TensorFlow model loaded.\n",
      "   Model initialized.\n",
      "\n",
      "\n",
      "Processing Image DSC03003_output.JPG (1):\n",
      "   2 modules detected.\n",
      "\n",
      "   Module 1 Perspective Refinement:\n",
      "      Image Size is 250 x 424 (106000 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 1 iterations - Ratio = 19.22% - Thresholds = (120, 240)\n",
      "        (0): Line Detection: 115 Detected - 67 Horizontal (0.10 +- 0.45 deg.) - 12 Vertical (90.65 +- 0.65 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 4 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = True; Right Angles = True\n",
      "        (0): Line Detection: 115 Detected - 49 Horizontal (0.04 +- 0.36 deg.) - 8 Vertical (90.25 +- 0.37 deg.)\n",
      "\n",
      "        (1): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = True; Right Angles = True\n",
      "\n",
      "   Module 2 Perspective Refinement:\n",
      "      Image Size is 241 x 409 (98569 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 2 iterations - Ratio = 19.90% - Thresholds = (119, 238)\n",
      "        (0): Line Detection: 113 Detected - 73 Horizontal (-0.25 +- 0.77 deg.) - 15 Vertical (92.16 +- 0.73 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 4 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = False; Vert. Parallel = False; Hori. Parallel = False; Right Angles = False\n",
      "        (0): Line Detection: 113 Detected - 62 Horizontal (-0.10 +- 0.62 deg.) - 6 Vertical (90.44 +- 0.70 deg.)\n",
      "\n",
      "        (1): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (1): Line Detection: 113 Detected - 59 Horizontal (-0.21 +- 1.12 deg.) - 6 Vertical (90.02 +- 0.37 deg.)\n",
      "\n",
      "        (2): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (2): Line Detection: 113 Detected - 56 Horizontal (-0.06 +- 0.66 deg.) - 6 Vertical (90.02 +- 0.35 deg.)\n",
      "\n",
      "        (3): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (3): Line Detection: 113 Detected - 63 Horizontal (-0.09 +- 1.09 deg.) - 9 Vertical (90.07 +- 0.53 deg.)\n",
      "\n",
      "        (4): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (4): Line Detection: 113 Detected - 62 Horizontal (-0.17 +- 0.79 deg.) - 8 Vertical (90.20 +- 0.54 deg.)\n",
      "\n",
      "        (5): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (5): Line Detection: 113 Detected - 66 Horizontal (-0.11 +- 0.59 deg.) - 10 Vertical (90.00 +- 0.72 deg.)\n",
      "\n",
      "        (6): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (6): Line Detection: 113 Detected - 51 Horizontal (-0.55 +- 0.96 deg.) - 6 Vertical (90.13 +- 0.50 deg.)\n",
      "\n",
      "        (7): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (7): Line Detection: 113 Detected - 56 Horizontal (-0.75 +- 0.96 deg.) - 6 Vertical (90.02 +- 0.37 deg.)\n",
      "\n",
      "        (8): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (8): Line Detection: 113 Detected - 55 Horizontal (-0.68 +- 0.96 deg.) - 6 Vertical (90.02 +- 0.37 deg.)\n",
      "\n",
      "        (9): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (9): Line Detection: 113 Detected - 58 Horizontal (-0.65 +- 1.05 deg.) - 7 Vertical (90.34 +- 0.70 deg.)\n",
      "\n",
      "        (10): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (10): Line Detection: 113 Detected - 57 Horizontal (-0.54 +- 1.43 deg.) - 7 Vertical (90.08 +- 0.51 deg.)\n",
      "\n",
      "        (11): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (11): Line Detection: 113 Detected - 60 Horizontal (-0.68 +- 0.92 deg.) - 12 Vertical (90.09 +- 0.74 deg.)\n",
      "\n",
      "        (12): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (12): Line Detection: 113 Detected - 65 Horizontal (-0.11 +- 0.91 deg.) - 6 Vertical (90.27 +- 0.35 deg.)\n",
      "\n",
      "        (13): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (13): Line Detection: 113 Detected - 61 Horizontal (-0.23 +- 1.26 deg.) - 4 Vertical (90.43 +- 0.37 deg.)\n",
      "\n",
      "        (14): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (14): Line Detection: 113 Detected - 60 Horizontal (-0.30 +- 1.63 deg.) - 6 Vertical (89.84 +- 0.35 deg.)\n",
      "\n",
      "        (15): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (15): Line Detection: 113 Detected - 56 Horizontal (-0.13 +- 0.89 deg.) - 6 Vertical (90.25 +- 0.34 deg.)\n",
      "\n",
      "        (16): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (16): Line Detection: 113 Detected - 60 Horizontal (-0.08 +- 0.55 deg.) - 9 Vertical (90.08 +- 0.53 deg.)\n",
      "\n",
      "        (17): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (17): Line Detection: 113 Detected - 75 Horizontal (-0.21 +- 0.81 deg.) - 10 Vertical (90.35 +- 0.72 deg.)\n",
      "\n",
      "        (18): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "Insufficient vertical lines.\n",
      "        (18): Line Detection: 113 Detected - 51 Horizontal (-0.44 +- 1.48 deg.) - 5 Vertical (90.32 +- 0.21 deg.)\n",
      "\n",
      "        (19): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (19): Line Detection: 113 Detected - 52 Horizontal (-0.28 +- 1.25 deg.) - 6 Vertical (90.30 +- 0.60 deg.)\n",
      "\n",
      "        (20): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (20): Line Detection: 113 Detected - 53 Horizontal (-0.58 +- 1.66 deg.) - 7 Vertical (90.15 +- 0.49 deg.)\n",
      "\n",
      "        (21): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (21): Line Detection: 113 Detected - 49 Horizontal (-0.42 +- 1.66 deg.) - 6 Vertical (90.24 +- 0.33 deg.)\n",
      "\n",
      "        (22): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (22): Line Detection: 113 Detected - 52 Horizontal (-0.59 +- 1.30 deg.) - 9 Vertical (90.07 +- 0.55 deg.)\n",
      "\n",
      "        (23): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (23): Line Detection: 113 Detected - 59 Horizontal (-0.48 +- 1.39 deg.) - 12 Vertical (90.34 +- 0.87 deg.)\n",
      "\n",
      "        (24): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (24): Line Detection: 113 Detected - 65 Horizontal (0.05 +- 0.79 deg.) - 6 Vertical (90.54 +- 0.47 deg.)\n",
      "\n",
      "        (25): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (25): Line Detection: 113 Detected - 62 Horizontal (-0.31 +- 1.40 deg.) - 7 Vertical (90.18 +- 0.50 deg.)\n",
      "\n",
      "        (26): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (26): Line Detection: 113 Detected - 58 Horizontal (-0.07 +- 0.62 deg.) - 6 Vertical (90.02 +- 0.36 deg.)\n",
      "\n",
      "        (27): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (27): Line Detection: 113 Detected - 67 Horizontal (-0.07 +- 0.45 deg.) - 8 Vertical (89.97 +- 0.54 deg.)\n",
      "\n",
      "        (28): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = True; Right Angles = True\n",
      "        (28): Line Detection: 113 Detected - 64 Horizontal (-0.03 +- 0.47 deg.) - 9 Vertical (90.08 +- 0.65 deg.)\n",
      "\n",
      "        (29): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = True; Right Angles = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        (29): Line Detection: 113 Detected - 66 Horizontal (-0.01 +- 0.57 deg.) - 12 Vertical (90.27 +- 0.87 deg.)\n",
      "\n",
      "        (30): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (30): Line Detection: 113 Detected - 66 Horizontal (-1.45 +- 1.48 deg.) - 6 Vertical (90.15 +- 0.98 deg.)\n",
      "\n",
      "        (31): Horizontal = False; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (31): Line Detection: 113 Detected - 63 Horizontal (-1.42 +- 1.26 deg.) - 6 Vertical (90.27 +- 0.37 deg.)\n",
      "\n",
      "        (32): Horizontal = False; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (32): Line Detection: 113 Detected - 49 Horizontal (-1.60 +- 0.88 deg.) - 8 Vertical (90.37 +- 0.68 deg.)\n",
      "\n",
      "        (33): Horizontal = False; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (33): Line Detection: 113 Detected - 60 Horizontal (-1.58 +- 0.92 deg.) - 4 Vertical (90.12 +- 0.28 deg.)\n",
      "\n",
      "        (34): Horizontal = False; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (34): Line Detection: 113 Detected - 46 Horizontal (-1.44 +- 1.25 deg.) - 7 Vertical (89.99 +- 0.52 deg.)\n",
      "\n",
      "        (35): Horizontal = False; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (35): Line Detection: 113 Detected - 56 Horizontal (-1.65 +- 1.26 deg.) - 12 Vertical (90.06 +- 0.76 deg.)\n",
      "\n",
      "\n",
      "Processing Image DSC03013_output.JPG (2):\n",
      "   2 modules detected.\n",
      "\n",
      "   Module 1 Perspective Refinement:\n",
      "      Image Size is 270 x 528 (142560 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 1 iterations - Ratio = 16.09% - Thresholds = (79, 159)\n",
      "        (0): Line Detection: 87 Detected - 76 Horizontal (0.02 +- 0.28 deg.) - 4 Vertical (90.73 +- 0.17 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 2 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = True; Right Angles = True\n",
      "\n",
      "   Module 2 Perspective Refinement:\n",
      "      Image Size is 259 x 539 (139601 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 1 iterations - Ratio = 18.32% - Thresholds = (95, 190)\n",
      "        (0): Line Detection: 116 Detected - 106 Horizontal (0.12 +- 0.75 deg.) - 7 Vertical (90.56 +- 0.97 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 2 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (0): Line Detection: 116 Detected - 73 Horizontal (-0.01 +- 1.14 deg.) - 6 Vertical (89.95 +- 0.33 deg.)\n",
      "\n",
      "        (1): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (1): Line Detection: 116 Detected - 76 Horizontal (0.24 +- 0.75 deg.) - 6 Vertical (89.74 +- 0.34 deg.)\n",
      "\n",
      "        (2): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (2): Line Detection: 116 Detected - 71 Horizontal (0.01 +- 0.52 deg.) - 5 Vertical (89.65 +- 0.42 deg.)\n",
      "\n",
      "        (3): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (3): Line Detection: 116 Detected - 92 Horizontal (0.08 +- 0.74 deg.) - 6 Vertical (89.83 +- 0.37 deg.)\n",
      "\n",
      "        (4): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (4): Line Detection: 116 Detected - 89 Horizontal (0.03 +- 0.65 deg.) - 6 Vertical (89.82 +- 0.47 deg.)\n",
      "\n",
      "        (5): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "Insufficient vertical lines.\n",
      "        (5): Line Detection: 116 Detected - 81 Horizontal (0.40 +- 0.78 deg.) - 2 Vertical (89.64 +- 0.36 deg.)\n",
      "\n",
      "\n",
      "Processing Image DSC03021_output.JPG (3):\n",
      "   2 modules detected.\n",
      "\n",
      "   Module 1 Perspective Refinement:\n",
      "      Image Size is 246 x 402 (98892 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 1 iterations - Ratio = 17.49% - Thresholds = (113, 227)\n",
      "        (0): Line Detection: 83 Detected - 41 Horizontal (-0.97 +- 0.67 deg.) - 5 Vertical (90.10 +- 0.37 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 3 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "Insufficient vertical lines.\n",
      "        (0): Line Detection: 83 Detected - 40 Horizontal (-0.34 +- 0.53 deg.) - 2 Vertical (90.19 +- 0.19 deg.)\n",
      "\n",
      "        (1): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "Insufficient vertical lines.\n",
      "        (1): Line Detection: 83 Detected - 37 Horizontal (-0.35 +- 0.48 deg.) - 3 Vertical (89.73 +- 0.23 deg.)\n",
      "\n",
      "        (2): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = True; Right Angles = True\n",
      "\n",
      "   Module 2 Perspective Refinement:\n",
      "      Image Size is 243 x 404 (98172 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 5 iterations - Ratio = 19.64% - Thresholds = (138, 276)\n",
      "        (0): Line Detection: 98 Detected - 52 Horizontal (0.41 +- 0.91 deg.) - 10 Vertical (89.87 +- 0.54 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 2 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (0): Line Detection: 98 Detected - 45 Horizontal (-0.06 +- 0.35 deg.) - 6 Vertical (90.04 +- 0.36 deg.)\n",
      "\n",
      "        (1): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = True; Right Angles = True\n",
      "\n",
      "Processing Image DSC03022_output.JPG (4):\n",
      "   3 modules detected.\n",
      "\n",
      "   Module 1 Perspective Refinement:\n",
      "      Image Size is 245 x 396 (97020 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 1 iterations - Ratio = 19.26% - Thresholds = (115, 230)\n",
      "        (0): Line Detection: 94 Detected - 38 Horizontal (0.03 +- 0.12 deg.) - 6 Vertical (90.04 +- 0.35 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 2 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = True; Right Angles = True\n",
      "\n",
      "   Module 2 Perspective Refinement:\n",
      "      Image Size is 242 x 392 (94864 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 4 iterations - Ratio = 19.73% - Thresholds = (127, 255)\n",
      "        (0): Line Detection: 96 Detected - 51 Horizontal (0.25 +- 0.69 deg.) - 11 Vertical (89.70 +- 0.60 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 4 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (0): Line Detection: 96 Detected - 37 Horizontal (-1.26 +- 3.64 deg.) - 6 Vertical (90.11 +- 0.45 deg.)\n",
      "\n",
      "        (1): Horizontal = False; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (1): Line Detection: 96 Detected - 37 Horizontal (-1.85 +- 3.63 deg.) - 5 Vertical (90.00 +- 0.38 deg.)\n",
      "\n",
      "        (2): Horizontal = False; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (2): Line Detection: 96 Detected - 40 Horizontal (-1.63 +- 3.33 deg.) - 6 Vertical (89.89 +- 0.39 deg.)\n",
      "\n",
      "        (3): Horizontal = False; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (3): Line Detection: 96 Detected - 37 Horizontal (-1.34 +- 3.32 deg.) - 6 Vertical (90.11 +- 0.52 deg.)\n",
      "\n",
      "        (4): Horizontal = False; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (4): Line Detection: 96 Detected - 38 Horizontal (-1.54 +- 3.08 deg.) - 5 Vertical (89.52 +- 0.32 deg.)\n",
      "\n",
      "        (5): Horizontal = False; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (5): Line Detection: 96 Detected - 37 Horizontal (-1.56 +- 3.11 deg.) - 11 Vertical (89.87 +- 0.65 deg.)\n",
      "\n",
      "        (6): Horizontal = False; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (6): Line Detection: 96 Detected - 37 Horizontal (0.76 +- 0.63 deg.) - 7 Vertical (90.13 +- 0.70 deg.)\n",
      "\n",
      "        (7): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (7): Line Detection: 96 Detected - 38 Horizontal (0.69 +- 0.67 deg.) - 6 Vertical (89.74 +- 0.65 deg.)\n",
      "\n",
      "        (8): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        (8): Line Detection: 96 Detected - 43 Horizontal (0.66 +- 0.67 deg.) - 6 Vertical (90.06 +- 0.71 deg.)\n",
      "\n",
      "        (9): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (9): Line Detection: 96 Detected - 40 Horizontal (0.64 +- 0.65 deg.) - 4 Vertical (89.87 +- 0.30 deg.)\n",
      "\n",
      "        (10): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (10): Line Detection: 96 Detected - 43 Horizontal (0.60 +- 0.71 deg.) - 9 Vertical (89.78 +- 0.59 deg.)\n",
      "\n",
      "        (11): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (11): Line Detection: 96 Detected - 44 Horizontal (0.58 +- 0.66 deg.) - 10 Vertical (89.91 +- 0.70 deg.)\n",
      "\n",
      "        (12): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (12): Line Detection: 96 Detected - 40 Horizontal (0.74 +- 0.65 deg.) - 6 Vertical (89.83 +- 0.41 deg.)\n",
      "\n",
      "        (13): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (13): Line Detection: 96 Detected - 40 Horizontal (0.83 +- 0.53 deg.) - 7 Vertical (89.75 +- 0.56 deg.)\n",
      "\n",
      "        (14): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (14): Line Detection: 96 Detected - 42 Horizontal (0.80 +- 0.52 deg.) - 7 Vertical (89.71 +- 0.52 deg.)\n",
      "\n",
      "        (15): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (15): Line Detection: 96 Detected - 43 Horizontal (0.84 +- 0.62 deg.) - 8 Vertical (89.94 +- 0.52 deg.)\n",
      "\n",
      "        (16): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (16): Line Detection: 96 Detected - 40 Horizontal (0.69 +- 0.64 deg.) - 7 Vertical (89.77 +- 0.53 deg.)\n",
      "\n",
      "        (17): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (17): Line Detection: 96 Detected - 44 Horizontal (0.61 +- 0.83 deg.) - 11 Vertical (89.98 +- 0.62 deg.)\n",
      "\n",
      "        (18): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (18): Line Detection: 96 Detected - 45 Horizontal (0.06 +- 0.82 deg.) - 5 Vertical (89.64 +- 0.28 deg.)\n",
      "\n",
      "        (19): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (19): Line Detection: 96 Detected - 38 Horizontal (0.08 +- 0.79 deg.) - 7 Vertical (89.95 +- 0.43 deg.)\n",
      "\n",
      "        (20): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (20): Line Detection: 96 Detected - 44 Horizontal (0.01 +- 0.79 deg.) - 9 Vertical (89.58 +- 0.55 deg.)\n",
      "\n",
      "        (21): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (21): Line Detection: 96 Detected - 47 Horizontal (0.06 +- 0.93 deg.) - 5 Vertical (89.85 +- 0.25 deg.)\n",
      "\n",
      "        (22): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = False; Right Angles = True\n",
      "        (22): Line Detection: 96 Detected - 46 Horizontal (0.07 +- 0.81 deg.) - 8 Vertical (89.45 +- 1.00 deg.)\n",
      "\n",
      "        (23): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (23): Line Detection: 96 Detected - 49 Horizontal (0.09 +- 0.83 deg.) - 11 Vertical (89.93 +- 0.60 deg.)\n",
      "\n",
      "        (24): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (24): Line Detection: 96 Detected - 47 Horizontal (-0.16 +- 0.54 deg.) - 10 Vertical (89.78 +- 0.73 deg.)\n",
      "\n",
      "        (25): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = False; Right Angles = True\n",
      "        (25): Line Detection: 96 Detected - 50 Horizontal (-0.12 +- 0.38 deg.) - 8 Vertical (89.77 +- 0.41 deg.)\n",
      "\n",
      "        (26): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = True; Right Angles = True\n",
      "\n",
      "   Module 3 Perspective Refinement:\n",
      "      Image Size is 238 x 373 (88774 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 2 iterations - Ratio = 19.93% - Thresholds = (110, 220)\n",
      "        (0): Line Detection: 102 Detected - 70 Horizontal (0.05 +- 0.41 deg.) - 9 Vertical (89.66 +- 0.59 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 4 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = True; Right Angles = True\n",
      "        (0): Line Detection: 102 Detected - 39 Horizontal (0.22 +- 0.37 deg.) - 4 Vertical (90.13 +- 0.30 deg.)\n",
      "\n",
      "        (1): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = True; Right Angles = True\n",
      "\n",
      "Processing Image DSC03023_output.JPG (5):\n",
      "   4 modules detected.\n",
      "\n",
      "   Module 1 Perspective Refinement:\n",
      "      Image Size is 247 x 403 (99541 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 2 iterations - Ratio = 19.92% - Thresholds = (98, 196)\n",
      "        (0): Line Detection: 96 Detected - 39 Horizontal (-0.00 +- 0.20 deg.) - 9 Vertical (89.98 +- 0.44 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 4 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = True; Right Angles = True\n",
      "\n",
      "   Module 2 Perspective Refinement:\n",
      "      Image Size is 246 x 394 (96924 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 8 iterations - Ratio = 19.58% - Thresholds = (128, 257)\n",
      "        (0): Line Detection: 97 Detected - 55 Horizontal (-0.03 +- 0.30 deg.) - 10 Vertical (89.63 +- 0.67 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 2 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = True; Right Angles = True\n",
      "        (0): Line Detection: 97 Detected - 53 Horizontal (-0.04 +- 0.25 deg.) - 4 Vertical (90.37 +- 0.28 deg.)\n",
      "\n",
      "        (1): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = True; Right Angles = True\n",
      "\n",
      "   Module 3 Perspective Refinement:\n",
      "      Image Size is 241 x 372 (89652 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 2 iterations - Ratio = 19.82% - Thresholds = (105, 210)\n",
      "        (0): Line Detection: 98 Detected - 70 Horizontal (-0.25 +- 0.30 deg.) - 10 Vertical (90.38 +- 0.51 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 2 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = True; Right Angles = True\n",
      "        (0): Line Detection: 98 Detected - 63 Horizontal (-0.06 +- 0.25 deg.) - 13 Vertical (89.07 +- 0.81 deg.)\n",
      "\n",
      "        (1): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = True; Right Angles = True\n",
      "        (1): Line Detection: 98 Detected - 67 Horizontal (-0.05 +- 0.37 deg.) - 11 Vertical (88.93 +- 0.75 deg.)\n",
      "\n",
      "        (2): Horizontal = True; Vertical = False; Vert. Parallel = False; Hori. Parallel = True; Right Angles = True\n",
      "        (2): Line Detection: 98 Detected - 67 Horizontal (0.04 +- 0.35 deg.) - 10 Vertical (88.86 +- 0.91 deg.)\n",
      "\n",
      "        (3): Horizontal = True; Vertical = False; Vert. Parallel = False; Hori. Parallel = True; Right Angles = True\n",
      "        (3): Line Detection: 98 Detected - 45 Horizontal (0.01 +- 0.21 deg.) - 12 Vertical (89.09 +- 0.86 deg.)\n",
      "\n",
      "        (4): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = True; Right Angles = True\n",
      "        (4): Line Detection: 98 Detected - 46 Horizontal (-0.05 +- 0.22 deg.) - 11 Vertical (88.97 +- 0.80 deg.)\n",
      "\n",
      "        (5): Horizontal = True; Vertical = False; Vert. Parallel = False; Hori. Parallel = True; Right Angles = True\n",
      "        (5): Line Detection: 98 Detected - 51 Horizontal (-0.03 +- 0.20 deg.) - 11 Vertical (88.96 +- 0.82 deg.)\n",
      "\n",
      "\n",
      "   Module 4 Perspective Refinement:\n",
      "      Image Size is 241 x 371 (89411 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 1 iterations - Ratio = 19.31% - Thresholds = (104, 208)\n",
      "        (0): Line Detection: 94 Detected - 61 Horizontal (0.25 +- 0.50 deg.) - 7 Vertical (89.55 +- 0.47 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 2 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = True; Right Angles = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Image DSC03024_output.JPG (6):\n",
      "   2 modules detected.\n",
      "\n",
      "   Module 1 Perspective Refinement:\n",
      "      Image Size is 248 x 410 (101680 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 3 iterations - Ratio = 19.93% - Thresholds = (102, 204)\n",
      "        (0): Line Detection: 96 Detected - 41 Horizontal (-0.06 +- 0.15 deg.) - 6 Vertical (90.08 +- 0.42 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 4 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = True; Right Angles = True\n",
      "\n",
      "   Module 2 Perspective Refinement:\n",
      "      Image Size is 242 x 404 (97768 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 10 iterations - Ratio = 19.57% - Thresholds = (134, 269)\n",
      "        (0): Line Detection: 104 Detected - 56 Horizontal (-0.04 +- 0.32 deg.) - 10 Vertical (89.80 +- 0.56 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 2 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = True; Right Angles = True\n",
      "        (0): Line Detection: 104 Detected - 52 Horizontal (-0.12 +- 0.40 deg.) - 6 Vertical (90.31 +- 0.36 deg.)\n",
      "\n",
      "        (1): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = True; Right Angles = True\n",
      "\n",
      "Processing Image DSC03025_output.JPG (7):\n",
      "   2 modules detected.\n",
      "\n",
      "   Module 1 Perspective Refinement:\n",
      "      Image Size is 256 x 414 (105984 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 1 iterations - Ratio = 19.98% - Thresholds = (94, 189)\n",
      "        (0): Line Detection: 100 Detected - 51 Horizontal (-0.03 +- 0.17 deg.) - 6 Vertical (90.25 +- 0.32 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 3 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = True; Right Angles = True\n",
      "\n",
      "   Module 2 Perspective Refinement:\n",
      "      Image Size is 250 x 409 (102250 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 7 iterations - Ratio = 19.97% - Thresholds = (119, 238)\n",
      "        (0): Line Detection: 108 Detected - 52 Horizontal (0.08 +- 0.35 deg.) - 11 Vertical (89.82 +- 0.56 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 4 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = True; Vert. Parallel = False; Hori. Parallel = True; Right Angles = True\n",
      "        (0): Line Detection: 108 Detected - 58 Horizontal (0.06 +- 0.29 deg.) - 6 Vertical (90.24 +- 0.31 deg.)\n",
      "\n",
      "        (1): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = True; Right Angles = True\n",
      "\n",
      "Processing Image DSC03026_output.JPG (8):\n",
      "   1 modules detected.\n",
      "\n",
      "   Module 1 Perspective Refinement:\n",
      "      Image Size is 268 x 424 (113632 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 1 iterations - Ratio = 19.47% - Thresholds = (91, 183)\n",
      "        (0): Line Detection: 111 Detected - 63 Horizontal (0.10 +- 0.37 deg.) - 9 Vertical (90.30 +- 0.45 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 2 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = True; Right Angles = True\n",
      "\n",
      "Processing Image DSC03027_output.JPG (9):\n",
      "   1 modules detected.\n",
      "\n",
      "   Module 1 Perspective Refinement:\n",
      "      Image Size is 262 x 426 (111612 px.)\n",
      "\n",
      "      Line Detection/Selection in Original Image:\n",
      "\n",
      "        (0): Edge detection: 1 iterations - Ratio = 18.18% - Thresholds = (95, 191)\n",
      "        (0): Line Detection: 104 Detected - 51 Horizontal (0.00 +- 0.17 deg.) - 7 Vertical (89.93 +- 0.44 deg.)\n",
      "        (0): Line Selection: 4 Horizontal - 4 Vertical\n",
      "\n",
      "      Perspective Correction Testing:\n",
      "\n",
      "        (0): Horizontal = True; Vertical = True; Vert. Parallel = True; Hori. Parallel = True; Right Angles = True\n"
     ]
    }
   ],
   "source": [
    "#Detection Parameters\n",
    "probability_thresh = 0.5\n",
    "broaden_frac = 0.075                  # Scalar for the amount the detection box edges are dilated\n",
    "shard_images_count = 1\n",
    "pipeline_type = 'modules'\n",
    "\n",
    "#Update user\n",
    "print('Module Detection Setup:')\n",
    "\n",
    "#Load label map\n",
    "category_index = label_map_util.create_category_index_from_labelmap(path_to_labels, use_display_name=True)\n",
    "\n",
    "#Load image pipeline\n",
    "image_list = os.listdir(prelim_output_dir)\n",
    "image_list = [image_name for image_name in image_list if image_name.endswith('output'+images_ext)]\n",
    "image_ct = len(image_list)\n",
    "\n",
    "#Print update\n",
    "if image_ct > 0: \n",
    "    print(f'   {image_ct} images found in directory meeting image spec.')\n",
    "else:\n",
    "    print(f'   No images found in directory meeting spec. Check directories and input spec.')\n",
    "\n",
    "#Load frozen model into memory\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(path_to_frozen_graph, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "        print(f'   Frozen TensorFlow model loaded.')\n",
    "\n",
    "graph = detection_graph\n",
    "with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        ops = tf.get_default_graph().get_operations()\n",
    "        all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "        tensor_dict = {}\n",
    "        for key in [\n",
    "            'num_detections', 'detection_boxes', 'detection_scores',\n",
    "            'detection_classes', 'detection_masks'\n",
    "        ]:\n",
    "            tensor_name = key + ':0'\n",
    "            if tensor_name in all_tensor_names:\n",
    "                tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                    tensor_name)\n",
    "        if 'detection_masks' in tensor_dict:\n",
    "            # The following processing is only for single image\n",
    "            detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "            detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "            \n",
    "            # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "            real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "            detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "            detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "            detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "            detection_masks_reframed = tf.cast(\n",
    "                tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "            \n",
    "            # Follow the convention by adding back the batch dimension\n",
    "            tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "                detection_masks_reframed, 0)\n",
    "            \n",
    "        #Define Image Tensor\n",
    "        image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')   \n",
    "        print(f'   Model initialized.\\n')\n",
    "        \n",
    "        \n",
    "        #TEMPORARY - DEFINE IMAGE SIZE - FUTURE USE SIZE FROM PIPELINE\n",
    "        image_size = (resize_cols, resize_rows)\n",
    "        \n",
    "        #Iterate through images shards\n",
    "        it = 1\n",
    "        for image_name in image_list:\n",
    "            \n",
    "            #Initialize time tracking\n",
    "            batch_start_time = time.time()\n",
    "            \n",
    "            #User feedback\n",
    "            print(f'\\nProcessing Image {image_name} ({it}):')\n",
    "\n",
    "            #Load the images\n",
    "            image_root = os.path.splitext(image_name)[0]\n",
    "            image_path = os.path.join(prelim_output_dir, image_name)\n",
    "            image = im.open(image_path).resize(image_size)\n",
    "            np_image = [detect.load_image_into_numpy_array(image)]\n",
    "            cv_image = np_image[0].copy()\n",
    "            \n",
    "            #Run Detection for Image Set        \n",
    "            start_time = time.time()\n",
    "            outputs = detect.run_inference(sess, np_image, detection_graph, tensor_dict, image_tensor)           \n",
    "\n",
    "            #Count number of modules detected\n",
    "            num_modules = len(np.where(outputs[0]['detection_scores'] >= probability_thresh)[0])\n",
    "            print(f'   {num_modules} modules detected.')\n",
    "            \n",
    "            #Log Statistics\n",
    "            #statistics = log_statistics(statistics, probability_thresh, outputs, image_list, np_images)\n",
    "            \n",
    "            #Assemble Module\n",
    "            #np_images, image_list, outputs = assemble_module(np_images, image_list, outputs)\n",
    "            \n",
    "            #Generate Visualizations on images\n",
    "            np_image_labeled = detect.build_visualization(np_image, outputs, category_index, probability_thresh)\n",
    "            \n",
    "            #Saving the images\n",
    "            detect.output_images(np_image_labeled, [image_name], detect_output_dir)\n",
    "            \n",
    "            #Calculate module statistics\n",
    "            module_boxes = [outputs[0]['detection_boxes'][i] for i in range(0,num_modules)]\n",
    "            module_widths = [module_boxes[i][3] - module_boxes[i][1] for i in range(0,num_modules)]\n",
    "            module_heights = [module_boxes[i][2] - module_boxes[i][0] for i in range(0,num_modules)]\n",
    "            module_spacing = [module_boxes[i+1][3] - module_boxes[i][3] for i in range(0,num_modules-1)]\n",
    "            \n",
    "            #Crop the image to the box\n",
    "            crop_images = []\n",
    "            for m in range(0,num_modules):\n",
    "                \n",
    "                #Print update\n",
    "                print(f'\\n   Module {m+1} Perspective Refinement:')\n",
    "                \n",
    "                #Pull initial coordinates\n",
    "                box = module_boxes[m]\n",
    "                y1 = int(resize_cols * box[1])\n",
    "                y2 = int(resize_cols * box[3])\n",
    "                x1 = int(resize_rows * box[0])\n",
    "                x2 = int(resize_rows * box[2])\n",
    "                \n",
    "                #Broaden the box to account for errors\n",
    "                width = module_widths[m]\n",
    "                height = module_heights[m]\n",
    "                x_adj = int(height * broaden_frac * resize_rows)\n",
    "                y_adj = int(width * broaden_frac * resize_cols)\n",
    "                y1 -= y_adj\n",
    "                y2 += y_adj\n",
    "                x1 -= x_adj\n",
    "                x2 += x_adj\n",
    "                if x1 < 0:\n",
    "                    x1 = 0\n",
    "                if x2 > (resize_rows - 1):\n",
    "                    x2 = resize_rows - 1\n",
    "                if y1 < 0:\n",
    "                    y1 = 0\n",
    "                if y2 > (resize_cols - 1):\n",
    "                    y2 = resize_cols - 1\n",
    "                    \n",
    "                #Crop image and size\n",
    "                crop_image = cv_image[x1:x2, y1:y2, :]    \n",
    "                crop_rows, crop_cols, crop_channels = crop_image.shape\n",
    "                crop_pixels = crop_rows * crop_cols\n",
    "                \n",
    "                #Store and save cropped image\n",
    "                crop_images.append(crop_image)\n",
    "                module_root = image_root + f'-{m}'\n",
    "                output_name = module_root + images_ext\n",
    "                output_path = os.path.join(final_output_dir, output_name)\n",
    "                cv.imwrite(output_path, cv.cvtColor(crop_image, cv.COLOR_BGR2RGB))\n",
    "                \n",
    "                #Color space conversion\n",
    "                crop_gray = cv.cvtColor(crop_image, cv.COLOR_BGR2GRAY)\n",
    "                \n",
    "                #Final Perspective Correction\n",
    "                correctModulePerspective(crop_image, module_root, debug_dir=module_debug_output_dir, debug=debug)\n",
    "                \n",
    "                \n",
    "                #Debug outputs\n",
    "                if debug:\n",
    "                    \n",
    "                    #Create figure\n",
    "                    fig = plt.figure(num=f'Image {image_name} Preprocessing', tight_layout=True,figsize=[18, 9.5])\n",
    "                    gs = gridspec.GridSpec(4,5)\n",
    "                    mng = plt.get_current_fig_manager()\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "          \n",
    "            \n",
    "            \n",
    "            #Feedback\n",
    "            \n",
    "            \n",
    "            #Count which batch\n",
    "            it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 454,
   "position": {
    "height": "40px",
    "left": "1303px",
    "right": "20px",
    "top": "100px",
    "width": "609px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
