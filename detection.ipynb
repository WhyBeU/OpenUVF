{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hide_input": false,
    "id": "V8-yl-s-WKMG"
   },
   "source": [
    "# OpenUVF Crack Detector v1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Code adapted from object_detection_tutorial.ipynb by The TensorFlow Authors.\n",
    "\n",
    "\n",
    "Welcome to the object detection inference walkthrough!  This notebook will walk you step by step through the process of using a pre-trained model to detect objects in an image. Make sure to follow the [installation instructions](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md) before you start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFSqkTCdWKMI"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hV4P5gyTWKMI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RSDG\\Documents\\OpenUVF\\core\\object_detection\\utils\\visualization_utils.py:27: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n"
     ]
    }
   ],
   "source": [
    "#Import Essential Packages\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "#import tarfile\n",
    "import tensorflow as tf\n",
    "#import zipfile\n",
    "import time\n",
    "import logging\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "#Import Object Detection Utils\n",
    "from core import object_detection as object_detection\n",
    "from core.object_detection.utils import ops as utils_ops\n",
    "from core.object_detection.utils import label_map_util\n",
    "from core.object_detection.utils import visualization_utils as vis_util\n",
    "from core.utils.detection_utils import image_pipeline\n",
    "from core.utils.detection_utils import assemble_module\n",
    "from core.utils.detection_utils import initialize_statistics_dict\n",
    "from core.utils.detection_utils import log_statistics\n",
    "from core.utils.detection_utils import build_visualization\n",
    "\n",
    "#Ensure up to date version\n",
    "if StrictVersion(tf.__version__) < StrictVersion('1.9.0'):\n",
    "  raise ImportError('Please upgrade your TensorFlow installation to v1.9.* or later!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories\n",
    "\n",
    "Specify here the input and output directories.\n",
    "\n",
    "Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing `PATH_TO_FROZEN_GRAPH` to point to a new .pb file.\n",
    "\n",
    "Inputs:\n",
    "  1. path_to_frozen_graph (str): Path to the frozen detection graph.pb file representing the model you wish you to use.\n",
    "  2. path_to_labels (str): Path to the label map defined for your model.\n",
    "  3. images_dir (str): Path to the directory containing the images you wish to evaluate. Default value should be 'inputs/detection'\n",
    "  4. output_dir (str): Path to the directory where you wish the outputs to be saved. Default value should be 'outputs/detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_frozen_graph = 'core/models/C1C1(FRCNN_RN101_COCO)_v2/frozen_inference_graph.pb'\n",
    "path_to_labels = os.path.join('core/labels', '1_Class_label_map.pbtxt')\n",
    "images_dir = 'inputs/detection'\n",
    "output_dir = 'outputs/detection'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wy72mWwAWKMK"
   },
   "source": [
    "## Function Setup\n",
    "\n",
    "\n",
    "\n",
    "##### Pipeline Settings:\n",
    "The pipeline defines how the images are processed. The pipeline is broken down into groups and batches. Groups are images loaded into memory for processing, and is accordingly RAM limited. Batches are images fed to the detector and is primarily VRAM limited (if using a gpu).\n",
    " 1. pipeline_type (str): defines the mode used for processing images. \n",
    "      - Options:\n",
    "          1. modules-cells: performs cell level detection \n",
    "          2. modules\n",
    "          3. cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "v7m_NY_aWKMK"
   },
   "outputs": [],
   "source": [
    "# Environment Setup\n",
    "%matplotlib inline \n",
    "\n",
    "# Function Settings\n",
    "display = True\n",
    "shard_images = True\n",
    "shard_images_count = 72\n",
    "\n",
    "#Pipeline Settings\n",
    "pipeline_type = 'modules-cells'\n",
    "max_group_size = 72\n",
    "max_batch_size = 72\n",
    "\n",
    "\n",
    "#Optional Settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 3, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 68, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72]\n"
     ]
    }
   ],
   "source": [
    "images_list = image_pipeline(pipeline_type, images_dir, shard_images_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfn_tRFOWKMO"
   },
   "source": [
    "## Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBcB9QHLWKMU"
   },
   "source": [
    "## Load the frozen Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KezjCRVvWKMV"
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(path_to_frozen_graph, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1MVVTcLWKMW"
   },
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hDbpHkiWWKMX"
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(path_to_labels, use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EFsoUHvbWKMZ"
   },
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aSlYc3JkWKMa"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0_1AGhrWKMc"
   },
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "92BHxzcNWKMf"
   },
   "outputs": [],
   "source": [
    "def run_inference(np_images, graph, tensor_dict, image_tensor):\n",
    "      \n",
    "    #Defining Storage Array\n",
    "    outputs = []\n",
    "\n",
    "    #Tracking image count\n",
    "    nim = 1\n",
    "\n",
    "    #Iterate through directory\n",
    "    #for image_name in os.listdir(images_path):\n",
    "    for image_np in np_images:\n",
    "\n",
    "        # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "        image_np_expanded = np.expand_dims(image_np, axis=0)                         \n",
    "\n",
    "        # Run inference\n",
    "        output = sess.run(tensor_dict,\n",
    "                             feed_dict={image_tensor: np.expand_dims(image_np, 0)})\n",
    "\n",
    "        # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "        output['num_detections'] = int(output['num_detections'][0])\n",
    "        output['detection_classes'] = output[\n",
    "          'detection_classes'][0].astype(np.uint8)\n",
    "        output['detection_boxes'] = output['detection_boxes'][0]\n",
    "        output['detection_scores'] = output['detection_scores'][0]\n",
    "        if 'detection_masks' in output:\n",
    "            output['detection_masks'] = output['detection_masks'][0]\n",
    "\n",
    "        #Storing output\n",
    "        outputs.append(output)\n",
    "\n",
    "        #Updating image number\n",
    "        nim = nim + 1\n",
    "                \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crack Statistics \n",
    "\n",
    "This function accumulates crack statistics to allow better understanding of \n",
    "\n",
    "including:\n",
    "    1.  plant_num_cells (int) = total cells considered over the plant\n",
    "    2.  plant_num_modules (int) = total modules considered over the plant\n",
    "    3.  plant_num_cracks (int) = total cracks detected over the plant\n",
    "    4.  plant_num_cracks_per_cell (int) = average cracks per cell over the plant\n",
    "    5.  plant_num_cracks_per_cracked_cell (int) = average cracks per cracked cell over the plant\n",
    "    6.  plant_num_cracks_per_module (int) = average cracks per module over the plant\n",
    "    7.  plant_num_cracks_per_cell_index (1xnCells ndarray) = total number of cracks for each cell index over the plant\n",
    "    8.  module_num_cells (dict) = number of cells for each module considered\n",
    "    9.  module_num_cracks (dict) = number of cracks for each module considered\n",
    "    10. module_num_cracks_per_cell (list) = number of cracks\n",
    "    11. module_num_cracks_per_cell_index (list of 1xnCells ndarrays) = number of cracks for each module considered in each cell index\n",
    "    12. cell_num_cracks (list) = number of cracks in the cell\n",
    "    13. cell_crack_area (list of lists) = area for each crack in a cell\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    2. total number of cracked cells 9\n",
    "    3. average cracks per cracked cells\n",
    "    4. average cracks per all cells\n",
    "    5. total number of cracks per module\n",
    "    6. total number of cracked cells per module \n",
    "    7. total of cracks per cell index (to identify if there is a localization trend)\n",
    "    \n",
    "    returns statistics dictionary\n",
    "    \n",
    "    assumes outputs and image_list correspond 1 to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_statistics(statistics):\n",
    "    print('Plant:')\n",
    "    print('  # Modules               = ' + str(statistics['plant_num_modules']))\n",
    "    print('  # Cells                 = ' + str(statistics['plant_num_cells']))\n",
    "    print('  # Cracks                = ' + str(statistics['plant_num_cracks']))\n",
    "    print('  # Cracked Cells         = ' + str(statistics['plant_num_cracked_cells']))\n",
    "    print('  # Cracks/Cell           = ' + str(statistics['plant_num_cracks_per_cell']))\n",
    "    print('  # Cracks/Cracked-Cell   = ' + str(statistics['plant_num_cracks_per_cracked_cell']))\n",
    "    print('  # Cracks/Module         = ' + str(statistics['plant_num_cracks_per_module']))\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_images(np_images, image_list):\n",
    "\n",
    "    for i in range(len(image_list)):\n",
    "\n",
    "        #Pull image and name\n",
    "        image_np = np_images[i]        \n",
    "        image_name = image_list[i]\n",
    "        \n",
    "        print(type(image_np))\n",
    "        #Save Image to output directory\n",
    "        image_out = Image.fromarray(image_np)\n",
    "        image_out.save(os.path.join(output_dir, image_name))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3a5wMHN8WKMh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 1 Processed successfully!\n",
      "Batch 2 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 2 Processed successfully!\n",
      "Batch 3 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 3 Processed successfully!\n",
      "Batch 4 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 4 Processed successfully!\n",
      "Batch 5 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 5 Processed successfully!\n",
      "Batch 6 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 6 Processed successfully!\n",
      "Batch 7 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 7 Processed successfully!\n",
      "Batch 8 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 8 Processed successfully!\n",
      "Batch 9 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 9 Processed successfully!\n",
      "Batch 10 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 10 Processed successfully!\n",
      "Batch 11 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 11 Processed successfully!\n",
      "Batch 12 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 12 Processed successfully!\n",
      "Batch 13 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 13 Processed successfully!\n",
      "Batch 14 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 14 Processed successfully!\n",
      "Batch 15 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 15 Processed successfully!\n",
      "Batch 16 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 16 Processed successfully!\n",
      "Batch 17 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 17 Processed successfully!\n",
      "Batch 18 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 18 Processed successfully!\n",
      "Batch 19 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 19 Processed successfully!\n",
      "Batch 20 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 20 Processed successfully!\n",
      "Batch 21 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 21 Processed successfully!\n",
      "Batch 22 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 22 Processed successfully!\n",
      "Batch 23 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 23 Processed successfully!\n",
      "Batch 24 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 24 Processed successfully!\n",
      "Batch 25 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 25 Processed successfully!\n",
      "Batch 26 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 26 Processed successfully!\n",
      "Batch 27 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 27 Processed successfully!\n",
      "Batch 28 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 28 Processed successfully!\n",
      "Batch 29 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 29 Processed successfully!\n",
      "Batch 30 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 30 Processed successfully!\n",
      "Batch 31 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 31 Processed successfully!\n",
      "Batch 32 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 32 Processed successfully!\n",
      "Batch 33 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 33 Processed successfully!\n",
      "Batch 34 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 34 Processed successfully!\n",
      "Batch 35 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 35 Processed successfully!\n",
      "Batch 36 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 36 Processed successfully!\n",
      "Batch 37 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 37 Processed successfully!\n",
      "Batch 38 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 38 Processed successfully!\n",
      "Batch 39 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 39 Processed successfully!\n",
      "Batch 40 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 40 Processed successfully!\n",
      "Batch 41 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 41 Processed successfully!\n",
      "Batch 42 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 42 Processed successfully!\n",
      "Batch 43 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 43 Processed successfully!\n",
      "Batch 44 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 44 Processed successfully!\n",
      "Batch 45 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 45 Processed successfully!\n",
      "Batch 46 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 46 Processed successfully!\n",
      "Batch 47 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 47 Processed successfully!\n",
      "Batch 48 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 48 Processed successfully!\n",
      "Batch 49 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 49 Processed successfully!\n",
      "Batch 50 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 50 Processed successfully!\n",
      "Batch 51 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 51 Processed successfully!\n",
      "Batch 52 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 52 Processed successfully!\n",
      "Batch 53 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 53 Processed successfully!\n",
      "Batch 54 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 54 Processed successfully!\n",
      "Batch 55 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 55 Processed successfully!\n",
      "Batch 56 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 56 Processed successfully!\n",
      "Batch 57 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 57 Processed successfully!\n",
      "Batch 58 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 58 Processed successfully!\n",
      "Batch 59 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 59 Processed successfully!\n",
      "Batch 60 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 60 Processed successfully!\n",
      "Batch 61 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 61 Processed successfully!\n",
      "Batch 62 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 62 Processed successfully!\n",
      "Batch 63 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 63 Processed successfully!\n",
      "Batch 64 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 64 Processed successfully!\n",
      "Batch 65 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 65 Processed successfully!\n",
      "Batch 66 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 66 Processed successfully!\n",
      "Batch 67 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 67 Processed successfully!\n",
      "Batch 68 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 68 Processed successfully!\n",
      "Batch 69 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 69 Processed successfully!\n",
      "Batch 70 Processing...\n"
     ]
    }
   ],
   "source": [
    "# Defining variables\n",
    "statistics = initialize_statistics_dict()\n",
    "\n",
    "# Optional inputs\n",
    "probability_thresh = .5\n",
    "\n",
    "\n",
    "#Execution Tracking\n",
    "execution_times = dict(full=0, batch=[])\n",
    "full_start_time = time.time()\n",
    "\n",
    "# Get handles to input and output tensors\n",
    "graph = detection_graph\n",
    "with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        ops = tf.get_default_graph().get_operations()\n",
    "        all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "        tensor_dict = {}\n",
    "        for key in [\n",
    "            'num_detections', 'detection_boxes', 'detection_scores',\n",
    "            'detection_classes', 'detection_masks'\n",
    "        ]:\n",
    "            tensor_name = key + ':0'\n",
    "            if tensor_name in all_tensor_names:\n",
    "                tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                    tensor_name)\n",
    "        if 'detection_masks' in tensor_dict:\n",
    "            # The following processing is only for single image\n",
    "            detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "            detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "            \n",
    "            # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "            real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "            detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "            detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "            detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "            detection_masks_reframed = tf.cast(\n",
    "                tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "            \n",
    "            # Follow the convention by adding back the batch dimension\n",
    "            tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "                detection_masks_reframed, 0)\n",
    "            \n",
    "        #Define Image Tensor\n",
    "        image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')   \n",
    "        \n",
    "        #TEMPORARY - DEFINE IMAGE SIZE - FUTURE USE SIZE FROM PIPELINE\n",
    "        image_size = (150, 150)\n",
    "        \n",
    "        #Iterate through images shards\n",
    "        batch = 1\n",
    "        for image_list in images_list:\n",
    "            \n",
    "            #Initialize time tracking\n",
    "            batch_start_time = time.time()\n",
    "            \n",
    "            #User feedback\n",
    "            print('Batch ' + str(batch) + ' Processing...')\n",
    "\n",
    "            #Load the images\n",
    "            np_images = []\n",
    "            for image_name in image_list:\n",
    "\n",
    "                #Load the image and convert to \n",
    "                image_path = os.path.join(images_dir, image_name)\n",
    "                image = Image.open(image_path).resize(image_size)\n",
    "                image_np = load_image_into_numpy_array(image)\n",
    "\n",
    "                #Append it to array\n",
    "                np_images.append(image_np)           \n",
    "\n",
    "            \n",
    "            #Run Detection for Image Set        \n",
    "            start_time = time.time()\n",
    "            outputs = run_inference(np_images, detection_graph, tensor_dict, image_tensor) \n",
    "            \n",
    "            #Log Statistics\n",
    "            statistics = log_statistics(statistics, probability_thresh, outputs, image_list, np_images)\n",
    "            \n",
    "            #Assemble Module\n",
    "            np_images, image_list, outputs = assemble_module(np_images, image_list, outputs)\n",
    "            \n",
    "            #Generate Visualizations on images\n",
    "            np_images_labeled = build_visualization(np_images, outputs, category_index, probability_thresh)\n",
    "            \n",
    "            #Saving the images\n",
    "            output_images(np_images_labeled, image_list)\n",
    "            \n",
    "            #Feedback\n",
    "            print('Batch ' + str(batch) + ' Processed successfully!')\n",
    "            \n",
    "            #Count which batch\n",
    "            batch+=1\n",
    "            \n",
    "            #Log Processing time\n",
    "            execution_times['batch'].append(time.time() - batch_start_time)\n",
    "            \n",
    "\n",
    "#Log total process time\n",
    "execution_times['full'] = time.time() - full_start_time\n",
    "            \n",
    "#Outputs\n",
    "output_statistics(statistics)\n",
    "print('Total Execution Time =         ' + str(execution_times['full']) + ' s')\n",
    "print('Mean Batch Execution Time =    ' + str(sum(execution_times['batch'])/float(len(execution_times['batch']))) + ' s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputting Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crack Visualization\n",
    "\n",
    "Optional Inputs:\n",
    "  1. max_figures (int): specifies the max number of pyplot figures that can be generated\n",
    "  2. images_sampled (int, int array, or str): specifies which images are displayed. Options:\n",
    "     1. 'random' - displays random images until max_figures is reached\n",
    "     2. 'first' - displays first set of images until max_figures is reached\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization function\n",
    "def visualize_images(images_list, outputs, max_figures=100, images_sampled='random', figure_size=(5,5)):\n",
    "\n",
    "    \n",
    "    #Defining images to display\n",
    "    image_ct = len(output)\n",
    "    \n",
    "\n",
    "    #Visualize and save images\n",
    "    i = 0;\n",
    "    for image_name in images_list:\n",
    "\n",
    "        #Pull Image and VisBox Data\n",
    "        output = outputs[i]\n",
    "        image_path = os.path.join(images_dir, image_name)\n",
    "        image = Image.open(image_path)\n",
    "        image_np = load_image_into_numpy_array(image)\n",
    "\n",
    "        #Apply Visualization Boxes with labels\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np,\n",
    "            output['detection_boxes'],\n",
    "            output['detection_classes'],\n",
    "            output['detection_scores'],\n",
    "            category_index,\n",
    "            instance_masks=output.get('detection_masks'),\n",
    "            use_normalized_coordinates=True,\n",
    "            line_thickness=2)\n",
    "\n",
    "        #Display images in figure\n",
    "        if i < 100 and display_output_sample:\n",
    "            plt.figure(figsize=figure_size)\n",
    "            plt.imshow(image_np)\n",
    "\n",
    "        #Save Image to output directory\n",
    "        image_out = Image.fromarray(image_np)    \n",
    "        image_out.save(os.path.join(output_dir, image_name))\n",
    "\n",
    "        #Increment i\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LQSEnEsPWKMj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "object_detection_tutorial.ipynb?workspaceId=ronnyvotel:python_inference::citc",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "576px",
    "left": "16px",
    "right": "20px",
    "top": "86px",
    "width": "338px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
