{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hide_input": false,
    "id": "V8-yl-s-WKMG"
   },
   "source": [
    "# OpenUVF Crack Detector \n",
    "\n",
    "   Copyright 2019 Southern Company. \n",
    "\n",
    "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "   you may not use this file except in compliance with the License.\n",
    "   You may obtain a copy of the License at\n",
    "\n",
    "       http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "   Unless required by applicable law or agreed to in writing, software\n",
    "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "   See the License for the specific language governing permissions and\n",
    "   limitations under the License.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This notebook executes crack detection on an input directory of module or cell images and provides utilities for assembling modules from cells and accumulating plant, module, and cell level statistics. In the future, automatic module/cell segmentation will be integrated into this script to simplify the process.\n",
    "\n",
    "For reasonably quick crack detection, it is recommended your computer have at least 8GB of RAM, a reasonably modern CPU, and a GPU. \n",
    "\n",
    "\n",
    "The notebook was adapted from object_detection_tutorial.ipynb by The TensorFlow Authors, which can be found in the core directory or on [Github](https://github.com/tensorflow/models/tree/master/research/object_detection). Please refer to the setup instructions [LINK] before using this script. If issues arise, please refer to the troubleshooting section first then search stackoverflow or github for solutions. Most issues will likely be related to your virtual environment or CUDA (if you are using a GPU).\n",
    "\n",
    "\n",
    "### Changelog\n",
    "1. Several additional imports added\n",
    "2. Input cells modified extensively and/or recreated\n",
    "3. Detection cell modified to allow multiple image inputs\n",
    "4. Visualization utility modified for more images \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFSqkTCdWKMI"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hV4P5gyTWKMI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhg19\\OpenUVF\\core\\object_detection\\utils\\visualization_utils.py:27: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n"
     ]
    }
   ],
   "source": [
    "#Import Essential Packages\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "#import tarfile\n",
    "import tensorflow as tf\n",
    "#import zipfile\n",
    "import time\n",
    "import logging\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "#Import Utility functions\n",
    "from core import object_detection as object_detection\n",
    "from core.object_detection.utils import ops as utils_ops\n",
    "from core.object_detection.utils import label_map_util\n",
    "from core.object_detection.utils import visualization_utils as vis_util\n",
    "from core.utils.detection_utils import image_pipeline\n",
    "from core.utils.detection_utils import assemble_module\n",
    "from core.utils.detection_utils import initialize_statistics_dict\n",
    "from core.utils.detection_utils import log_statistics\n",
    "from core.utils.detection_utils import build_visualization\n",
    "\n",
    "#Ensure up to date version\n",
    "if StrictVersion(tf.__version__) < StrictVersion('1.9.0'):\n",
    "  raise ImportError('Please upgrade your TensorFlow installation to v1.9.* or later!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories\n",
    "\n",
    "Specify here the input and output directories.\n",
    "\n",
    "### Inputs:\n",
    "  1. **path_to_frozen_graph** (str): Path to the frozen detection graph.pb file representing the model you wish you to use. Any model exported using the `export_inference_graph.py` tool can be loaded here. Pretrained models should be located in: `'core/models/'`\n",
    "  2. **path_to_labels** (str): Path to the label map defined for your model. Default choices are: \n",
    "  - `'core/labels/1_Class_label_map.pbtxt'`  \n",
    "  -`'core/labels/6_Class_label_map.pbtxt'` \n",
    "  3. **images_dir** (str): Path to the directory containing the images you wish to evaluate. Default value should be `'inputs/detection'`\n",
    "  4. **output_dir** (str): Path to the directory where you wish the outputs to be saved. Default value should be `'outputs/detection'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_frozen_graph = 'core/models/C1C1(SSD_MN_v1_COCO)_v2/frozen_inference_graph.pb'\n",
    "path_to_labels = 'core/labels/1_Class_label_map.pbtxt'\n",
    "images_dir = 'inputs/detection/cells'\n",
    "output_dir = 'outputs/detection'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wy72mWwAWKMK"
   },
   "source": [
    "## Function Setup\n",
    "\n",
    "\n",
    "\n",
    "##### Pipeline Settings:\n",
    "The pipeline defines how the images are processed. The pipeline is broken down into groups and batches. Groups are images loaded into memory for processing, and is accordingly RAM limited. Batches are images fed to the detector and is primarily VRAM limited (if using a gpu).\n",
    " 1. pipeline_type (str): defines the mode used for processing images. \n",
    "      - Options:\n",
    "          1. modules-cells: performs cell level detection \n",
    "          2. modules\n",
    "          3. cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "v7m_NY_aWKMK"
   },
   "outputs": [],
   "source": [
    "# Environment Setup\n",
    "%matplotlib inline \n",
    "\n",
    "# Function Settings\n",
    "display = True\n",
    "shard_images = True\n",
    "shard_images_count = 72\n",
    "\n",
    "#Pipeline Settings\n",
    "pipeline_type = 'modules-cells'\n",
    "max_group_size = 72\n",
    "max_batch_size = 72\n",
    "\n",
    "\n",
    "#Optional Settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A18791-3']\n",
      "[72]\n"
     ]
    }
   ],
   "source": [
    "images_list = image_pipeline(pipeline_type, images_dir, shard_images_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfn_tRFOWKMO"
   },
   "source": [
    "## Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBcB9QHLWKMU"
   },
   "source": [
    "## Load the frozen Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KezjCRVvWKMV"
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(path_to_frozen_graph, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1MVVTcLWKMW"
   },
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hDbpHkiWWKMX"
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(path_to_labels, use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EFsoUHvbWKMZ"
   },
   "source": [
    "## Helper code\n",
    "\n",
    "Unmodified from that released by The TensorFlow Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aSlYc3JkWKMa"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0_1AGhrWKMc"
   },
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "92BHxzcNWKMf"
   },
   "outputs": [],
   "source": [
    "def run_inference(np_images, graph, tensor_dict, image_tensor):\n",
    "      \n",
    "    #Defining Storage Array\n",
    "    outputs = []\n",
    "\n",
    "    #Tracking image count\n",
    "    nim = 1\n",
    "\n",
    "    #Iterate through directory\n",
    "    #for image_name in os.listdir(images_path):\n",
    "    for image_np in np_images:\n",
    "\n",
    "        # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "        image_np_expanded = np.expand_dims(image_np, axis=0)                         \n",
    "\n",
    "        # Run inference\n",
    "        output = sess.run(tensor_dict,\n",
    "                             feed_dict={image_tensor: np.expand_dims(image_np, 0)})\n",
    "\n",
    "        # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "        output['num_detections'] = int(output['num_detections'][0])\n",
    "        output['detection_classes'] = output[\n",
    "          'detection_classes'][0].astype(np.uint8)\n",
    "        output['detection_boxes'] = output['detection_boxes'][0]\n",
    "        output['detection_scores'] = output['detection_scores'][0]\n",
    "        if 'detection_masks' in output:\n",
    "            output['detection_masks'] = output['detection_masks'][0]\n",
    "\n",
    "        #Storing output\n",
    "        outputs.append(output)\n",
    "\n",
    "        #Updating image number\n",
    "        nim = nim + 1\n",
    "                \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crack Statistics \n",
    "\n",
    "This function accumulates crack statistics to allow better understanding of \n",
    "\n",
    "including:\n",
    "    1.  plant_num_cells (int) = total cells considered over the plant\n",
    "    2.  plant_num_modules (int) = total modules considered over the plant\n",
    "    3.  plant_num_cracks (int) = total cracks detected over the plant\n",
    "    4.  plant_num_cracks_per_cell (int) = average cracks per cell over the plant\n",
    "    5.  plant_num_cracks_per_cracked_cell (int) = average cracks per cracked cell over the plant\n",
    "    6.  plant_num_cracks_per_module (int) = average cracks per module over the plant\n",
    "    7.  plant_num_cracks_per_cell_index (1xnCells ndarray) = total number of cracks for each cell index over the plant\n",
    "    8.  module_num_cells (dict) = number of cells for each module considered\n",
    "    9.  module_num_cracks (dict) = number of cracks for each module considered\n",
    "    10. module_num_cracks_per_cell (list) = number of cracks\n",
    "    11. module_num_cracks_per_cell_index (list of 1xnCells ndarrays) = number of cracks for each module considered in each cell index\n",
    "    12. cell_num_cracks (list) = number of cracks in the cell\n",
    "    13. cell_crack_area (list of lists) = area for each crack in a cell\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    2. total number of cracked cells 9\n",
    "    3. average cracks per cracked cells\n",
    "    4. average cracks per all cells\n",
    "    5. total number of cracks per module\n",
    "    6. total number of cracked cells per module \n",
    "    7. total of cracks per cell index (to identify if there is a localization trend)\n",
    "    \n",
    "    returns statistics dictionary\n",
    "    \n",
    "    assumes outputs and image_list correspond 1 to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_statistics(statistics):\n",
    "    print('Plant:')\n",
    "    print('  # Modules               = ' + str(statistics['plant_num_modules']))\n",
    "    print('  # Cells                 = ' + str(statistics['plant_num_cells']))\n",
    "    print('  # Cracks                = ' + str(statistics['plant_num_cracks']))\n",
    "    print('  # Cracked Cells         = ' + str(statistics['plant_num_cracked_cells']))\n",
    "    print('  # Cracks/Cell           = ' + str(statistics['plant_num_cracks_per_cell']))\n",
    "    print('  # Cracks/Cracked-Cell   = ' + str(statistics['plant_num_cracks_per_cracked_cell']))\n",
    "    print('  # Cracks/Module         = ' + str(statistics['plant_num_cracks_per_module']))\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_images(np_images, image_list):\n",
    "\n",
    "    for i in range(len(image_list)):\n",
    "\n",
    "        #Pull image and name\n",
    "        image_np = np_images[i]        \n",
    "        image_name = image_list[i]\n",
    "        \n",
    "        print(type(image_np))\n",
    "        #Save Image to output directory\n",
    "        image_out = Image.fromarray(image_np)\n",
    "        image_out.save(os.path.join(output_dir, image_name))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3a5wMHN8WKMh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 Processing...\n",
      "<class 'numpy.ndarray'>\n",
      "Batch 1 Processed successfully!\n",
      "Plant:\n",
      "  # Modules               = 1\n",
      "  # Cells                 = 72\n",
      "  # Cracks                = 72\n",
      "  # Cracked Cells         = 19\n",
      "  # Cracks/Cell           = 1.0149253731343284\n",
      "  # Cracks/Cracked-Cell   = 3.5789473684210527\n",
      "  # Cracks/Module         = 68.0\n",
      "Total Execution Time =         7.730875730514526 s\n",
      "Mean Batch Execution Time =    6.685817003250122 s\n",
      "{'plant_num_cells': 72, 'plant_num_modules': 1, 'plant_num_cracks': 72, 'plant_num_cracks_per_cell': 1.0149253731343284, 'plant_num_cracked_cells': 19, 'plant_num_cracks_per_cracked_cell': 3.5789473684210527, 'plant_num_cracks_per_module': 68.0, 'plant_num_cracks_per_cell_index': [2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 3, 3, 0, 0, 0, 2, 2, 0, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0], 'modules': {'A18791-3': {'num_cells': 19, 'num_cracks': 44, 'num_cracks_per_cell_index': [2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 3, 3, 0, 0, 0, 2, 2, 0, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0]}}, 'cell_num_cracks': [2, 2, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 1, 0, 1, 2, 2, 3, 3, 0, 0, 1, 0, 2, 2, 0, 3, 3, 2, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 2, 3, 0, 1, 0, 2, 0, 1, 2, 1, 0, 0, 0, 1, 1, 3, 0, 1, 1, 2, 1, 1, 0, 1, 1], 'cell_crack_area': [[0.13398607, 0.027919747], [0.028759131, 0.024960188], [0.14385891], [], [0.0567046], [], [], [], [], [0.01677774], [0.032211963], [0.022129316], [0.2658666], [0.06305056, 0.043679204], [0.028104104, 0.121927224], [0.23706175], [], [0.028058762], [0.25677884, 0.025154123], [0.056119673, 0.0820173], [0.1982927, 0.02163808, 0.022525495], [0.120286755, 0.052523438, 0.017412616], [], [], [0.039992917], [], [0.33440894, 0.113650076], [0.29580513, 0.02065631], [], [0.028748045, 0.01579349, 0.041397985], [0.045048837, 0.0067896694, 0.009297629], [0.018888146, 0.023493381], [], [0.009738627], [], [0.04492735], [0.040824786], [0.007912261], [], [0.014474936], [], [], [0.019892106], [0.023354143], [], [], [0.31343848], [0.31672925, 0.17672162], [0.05284483, 0.34317887, 0.093275845], [], [0.016422035], [], [0.03344143, 0.064882174], [], [0.14105375], [0.040813945, 0.06892112], [0.06290327], [], [], [], [0.014252686], [0.5035803], [0.04373685, 0.013570457, 0.2899259], [], [0.02211746], [0.03242336], [0.17503564, 0.03412235], [0.14103119], [0.06643315], [], [0.008453483], [0.06491974]]}\n"
     ]
    }
   ],
   "source": [
    "# Defining variables\n",
    "statistics = initialize_statistics_dict()\n",
    "\n",
    "# Optional inputs\n",
    "probability_thresh = .5\n",
    "\n",
    "\n",
    "#Execution Tracking\n",
    "execution_times = dict(full=0, batch=[])\n",
    "full_start_time = time.time()\n",
    "\n",
    "# Get handles to input and output tensors\n",
    "graph = detection_graph\n",
    "with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        ops = tf.get_default_graph().get_operations()\n",
    "        all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "        tensor_dict = {}\n",
    "        for key in [\n",
    "            'num_detections', 'detection_boxes', 'detection_scores',\n",
    "            'detection_classes', 'detection_masks'\n",
    "        ]:\n",
    "            tensor_name = key + ':0'\n",
    "            if tensor_name in all_tensor_names:\n",
    "                tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                    tensor_name)\n",
    "        if 'detection_masks' in tensor_dict:\n",
    "            # The following processing is only for single image\n",
    "            detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "            detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "            \n",
    "            # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "            real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "            detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "            detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "            detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "            detection_masks_reframed = tf.cast(\n",
    "                tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "            \n",
    "            # Follow the convention by adding back the batch dimension\n",
    "            tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "                detection_masks_reframed, 0)\n",
    "            \n",
    "        #Define Image Tensor\n",
    "        image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')   \n",
    "        \n",
    "        #TEMPORARY - DEFINE IMAGE SIZE - FUTURE USE SIZE FROM PIPELINE\n",
    "        image_size = (150, 150)\n",
    "        \n",
    "        #Iterate through images shards\n",
    "        batch = 1\n",
    "        for image_list in images_list:\n",
    "            \n",
    "            #Initialize time tracking\n",
    "            batch_start_time = time.time()\n",
    "            \n",
    "            #User feedback\n",
    "            print('Batch ' + str(batch) + ' Processing...')\n",
    "\n",
    "            #Load the images\n",
    "            np_images = []\n",
    "            for image_name in image_list:\n",
    "\n",
    "                #Load the image and convert to \n",
    "                image_path = os.path.join(images_dir, image_name)\n",
    "                image = Image.open(image_path).resize(image_size)\n",
    "                image_np = load_image_into_numpy_array(image)\n",
    "\n",
    "                #Append it to array\n",
    "                np_images.append(image_np)           \n",
    "\n",
    "            \n",
    "            #Run Detection for Image Set        \n",
    "            start_time = time.time()\n",
    "            outputs = run_inference(np_images, detection_graph, tensor_dict, image_tensor) \n",
    "            \n",
    "            #Log Statistics\n",
    "            statistics = log_statistics(statistics, probability_thresh, outputs, image_list, np_images)\n",
    "            \n",
    "            #Assemble Module\n",
    "            np_images, image_list, outputs = assemble_module(np_images, image_list, outputs)\n",
    "            \n",
    "            #Generate Visualizations on images\n",
    "            np_images_labeled = build_visualization(np_images, outputs, category_index, probability_thresh)\n",
    "            \n",
    "            #Saving the images\n",
    "            output_images(np_images_labeled, image_list)\n",
    "            \n",
    "            #Feedback\n",
    "            print('Batch ' + str(batch) + ' Processed successfully!')\n",
    "            \n",
    "            #Count which batch\n",
    "            batch+=1\n",
    "            \n",
    "            #Log Processing time\n",
    "            execution_times['batch'].append(time.time() - batch_start_time)\n",
    "            \n",
    "\n",
    "#Log total process time\n",
    "execution_times['full'] = time.time() - full_start_time\n",
    "            \n",
    "#Outputs\n",
    "output_statistics(statistics)\n",
    "print('Total Execution Time =         ' + str(execution_times['full']) + ' s')\n",
    "print('Mean Batch Execution Time =    ' + str(sum(execution_times['batch'])/float(len(execution_times['batch']))) + ' s')\n",
    "print(statistics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputting Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plant_num_cells': 72, 'plant_num_modules': 1, 'plant_num_cracks': 72, 'plant_num_cracks_per_cell': 1.0149253731343284, 'plant_num_cracked_cells': 19, 'plant_num_cracks_per_cracked_cell': 3.5789473684210527, 'plant_num_cracks_per_module': 68.0, 'plant_num_cracks_per_cell_index': [2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 3, 3, 0, 0, 0, 2, 2, 0, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0], 'modules': {'A18791-3': {'num_cells': 19, 'num_cracks': 44, 'num_cracks_per_cell_index': [2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 3, 3, 0, 0, 0, 2, 2, 0, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0]}}, 'cell_num_cracks': [2, 2, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 1, 0, 1, 2, 2, 3, 3, 0, 0, 1, 0, 2, 2, 0, 3, 3, 2, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 2, 3, 0, 1, 0, 2, 0, 1, 2, 1, 0, 0, 0, 1, 1, 3, 0, 1, 1, 2, 1, 1, 0, 1, 1], 'cell_crack_area': [[0.13398607, 0.027919747], [0.028759131, 0.024960188], [0.14385891], [], [0.0567046], [], [], [], [], [0.01677774], [0.032211963], [0.022129316], [0.2658666], [0.06305056, 0.043679204], [0.028104104, 0.121927224], [0.23706175], [], [0.028058762], [0.25677884, 0.025154123], [0.056119673, 0.0820173], [0.1982927, 0.02163808, 0.022525495], [0.120286755, 0.052523438, 0.017412616], [], [], [0.039992917], [], [0.33440894, 0.113650076], [0.29580513, 0.02065631], [], [0.028748045, 0.01579349, 0.041397985], [0.045048837, 0.0067896694, 0.009297629], [0.018888146, 0.023493381], [], [0.009738627], [], [0.04492735], [0.040824786], [0.007912261], [], [0.014474936], [], [], [0.019892106], [0.023354143], [], [], [0.31343848], [0.31672925, 0.17672162], [0.05284483, 0.34317887, 0.093275845], [], [0.016422035], [], [0.03344143, 0.064882174], [], [0.14105375], [0.040813945, 0.06892112], [0.06290327], [], [], [], [0.014252686], [0.5035803], [0.04373685, 0.013570457, 0.2899259], [], [0.02211746], [0.03242336], [0.17503564, 0.03412235], [0.14103119], [0.06643315], [], [0.008453483], [0.06491974]]}\n"
     ]
    }
   ],
   "source": [
    "print(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crack Visualization\n",
    "\n",
    "Optional Inputs:\n",
    "  1. max_figures (int): specifies the max number of pyplot figures that can be generated\n",
    "  2. images_sampled (int, int array, or str): specifies which images are displayed. Options:\n",
    "     1. 'random' - displays random images until max_figures is reached\n",
    "     2. 'first' - displays first set of images until max_figures is reached\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization function\n",
    "def visualize_images(images_list, outputs, max_figures=100, images_sampled='random', figure_size=(5,5)):\n",
    "\n",
    "    \n",
    "    #Defining images to display\n",
    "    image_ct = len(output)\n",
    "    \n",
    "\n",
    "    #Visualize and save images\n",
    "    i = 0;\n",
    "    for image_name in images_list:\n",
    "\n",
    "        #Pull Image and VisBox Data\n",
    "        output = outputs[i]\n",
    "        image_path = os.path.join(images_dir, image_name)\n",
    "        image = Image.open(image_path)\n",
    "        image_np = load_image_into_numpy_array(image)\n",
    "\n",
    "        #Apply Visualization Boxes with labels\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np,\n",
    "            output['detection_boxes'],\n",
    "            output['detection_classes'],\n",
    "            output['detection_scores'],\n",
    "            category_index,\n",
    "            instance_masks=output.get('detection_masks'),\n",
    "            use_normalized_coordinates=True,\n",
    "            line_thickness=2)\n",
    "\n",
    "        #Display images in figure\n",
    "        if i < 100 and display_output_sample:\n",
    "            plt.figure(figsize=figure_size)\n",
    "            plt.imshow(image_np)\n",
    "\n",
    "        #Save Image to output directory\n",
    "        image_out = Image.fromarray(image_np)    \n",
    "        image_out.save(os.path.join(output_dir, image_name))\n",
    "\n",
    "        #Increment i\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LQSEnEsPWKMj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "object_detection_tutorial.ipynb?workspaceId=ronnyvotel:python_inference::citc",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "576px",
    "left": "16px",
    "right": "20px",
    "top": "86px",
    "width": "338px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
